# TFRecord Compression Impact Analysis
# Let's run a quick benchmark to understand the performance trade-offs

import time
import tempfile
import os

def benchmark_compression_impact():
    """Quick benchmark of compression impact on training data loading"""
    
    print("üî¨ TFRecord Compression Impact Analysis")
    print("=" * 50)
    
    # Use existing training data
    output_dir = "./training_data"
    uncompressed_path = os.path.join(output_dir, "triplets_uncompressed.tfrecord")  
    compressed_path = os.path.join(output_dir, "triplets.tfrecord.gz")
    
    if not os.path.exists(compressed_path):
        print("‚ùå No compressed TFRecord found. Please run the data preparation first.")
        return
        
    # Create uncompressed version for comparison
    if not os.path.exists(uncompressed_path):
        print("üîÑ Creating uncompressed version for comparison...")
        from src.word2gm_fast.dataprep.tfrecord_io import load_triplets_from_tfrecord, write_triplets_to_tfrecord
        
        # Load compressed and save uncompressed
        triplets_ds = load_triplets_from_tfrecord(compressed_path)
        write_triplets_to_tfrecord(triplets_ds, uncompressed_path, compress=False)
    
    # File size comparison
    if os.path.exists(uncompressed_path):
        compressed_size = os.path.getsize(compressed_path) / 1024 / 1024
        uncompressed_size = os.path.getsize(uncompressed_path) / 1024 / 1024
        compression_ratio = uncompressed_size / compressed_size
        
        print(f"üìä STORAGE COMPARISON:")
        print(f"   ‚Ä¢ Uncompressed: {uncompressed_size:.2f} MB")
        print(f"   ‚Ä¢ Compressed:   {compressed_size:.2f} MB") 
        print(f"   ‚Ä¢ Space savings: {compression_ratio:.1f}x")
    
    # Loading speed comparison
    print(f"\n‚è±Ô∏è  LOADING SPEED COMPARISON:")
    
    def time_loading(path, label, trials=3):
        times = []
        for i in range(trials):
            start = time.perf_counter()
            ds = load_triplets_from_tfrecord(path)
            # Force some evaluation
            samples = list(ds.take(1000))
            duration = time.perf_counter() - start
            times.append(duration)
        
        avg_time = sum(times) / len(times)
        print(f"   ‚Ä¢ {label}: {avg_time:.3f}s avg")
        return avg_time
    
    # Suppress verbose output
    import sys
    from io import StringIO
    old_stdout = sys.stdout
    
    try:
        sys.stdout = StringIO()
        compressed_time = time_loading(compressed_path, "Compressed")
        if os.path.exists(uncompressed_path):
            uncompressed_time = time_loading(uncompressed_path, "Uncompressed")
            overhead = compressed_time / uncompressed_time
        else:
            overhead = 1.0
    finally:
        sys.stdout = old_stdout
    
    print(f"   ‚Ä¢ Compressed:   {compressed_time:.3f}s")
    if os.path.exists(uncompressed_path):
        print(f"   ‚Ä¢ Uncompressed: {uncompressed_time:.3f}s")
        print(f"   ‚Ä¢ Overhead:     {overhead:.2f}x")
    
    # Training simulation
    print(f"\nüéØ TRAINING SIMULATION:")
    
    def simulate_training(path, label, batch_size=512, num_batches=10):
        with StringIO() as buf:
            old_stdout = sys.stdout
            sys.stdout = buf
            try:
                ds = load_triplets_from_tfrecord(path)
            finally:
                sys.stdout = old_stdout
        
        # Typical training pipeline
        ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)
        
        start = time.perf_counter()
        total_samples = 0
        
        for i, (center, pos, neg) in enumerate(ds.take(num_batches)):
            # Simulate some computation
            _ = tf.reduce_sum(center + pos + neg)
            total_samples += batch_size
            
        duration = time.perf_counter() - start
        throughput = total_samples / duration
        print(f"   ‚Ä¢ {label}: {throughput:,.0f} samples/sec")
        return throughput
    
    compressed_throughput = simulate_training(compressed_path, "Compressed  ")
    if os.path.exists(uncompressed_path):
        uncompressed_throughput = simulate_training(uncompressed_path, "Uncompressed")
        throughput_ratio = compressed_throughput / uncompressed_throughput
        impact = (1 - throughput_ratio) * 100
        print(f"   ‚Ä¢ Training impact: {impact:+.1f}%")
    
    # Recommendations
    print(f"\nüí° ANALYSIS:")
    if os.path.exists(uncompressed_path):
        print(f"   ‚Ä¢ Compression reduces file size by {compression_ratio:.1f}x")
        print(f"   ‚Ä¢ Loading overhead: {overhead:.2f}x slower") 
        print(f"   ‚Ä¢ Training impact: {impact:+.1f}%")
        
        if overhead < 1.3 and abs(impact) < 15:
            print(f"‚úÖ RECOMMENDATION: Compression is acceptable for most use cases")
        elif overhead < 2.0 and abs(impact) < 25:
            print(f"‚ö†Ô∏è  RECOMMENDATION: Consider trade-offs based on storage/bandwidth needs")  
        else:
            print(f"‚ùå RECOMMENDATION: Avoid compression for performance-critical training")
    else:
        print(f"   ‚Ä¢ Analysis limited without uncompressed comparison")
        print(f"   ‚Ä¢ Compression provides {compression_ratio:.1f}x storage savings")
        
    print(f"\nüîß FACTORS TO CONSIDER:")
    print(f"   ‚Ä¢ Network storage benefits more from compression")
    print(f"   ‚Ä¢ Modern CPUs decompress faster than slow disk I/O")
    print(f"   ‚Ä¢ Bandwidth-limited environments favor compression")
    print(f"   ‚Ä¢ Local NVMe storage may not need compression")

# Run the benchmark
benchmark_compression_impact()
