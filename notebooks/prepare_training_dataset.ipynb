{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d3ce6ba",
   "metadata": {},
   "source": [
    "# Word2GM Training Data Pipeline\n",
    "\n",
    "**Pipeline: Corpus file → TFRecord training artifacts (triplets and vocabulary)**\n",
    "\n",
    "Use this notebook to prepare a Google 5gram corpora for Word2GM skip-gram training.\n",
    "\n",
    "## Pipeline Workflow\n",
    "\n",
    "1. **Input**: Preprocessed corpus file (e.g., `2019.txt`) in `/vast` NVMe storage\n",
    "2. **Processing**: TensorFlow-native filtering, vocabulary building, and triplet generation\n",
    "3. **Output**: TFRecord artifacts in organized subdirectories (e.g., `2019_artifacts/`)\n",
    "\n",
    "### **Artifact Storage**\n",
    "The pipeline creates year-specific subdirectories alongside the original text corpora:\n",
    "<pre>\n",
    "/vast/edk202/NLP_corpora/.../data/\n",
    "├── 2018.txt\n",
    "├── 2019.txt\n",
    "├── 2020.txt\n",
    "├── 2018_artifacts/\n",
    "│   ├── triplets.tfrecord.gz\n",
    "│   └── vocab.tfrecord.gz\n",
    "├── 2019_artifacts/\n",
    "│   ├── triplets.tfrecord.gz\n",
    "│   └── vocab.tfrecord.gz\n",
    "└── 2020_artifacts/\n",
    "    ├── triplets.tfrecord.gz\n",
    "    └── vocab.tfrecord.gz\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d49f604",
   "metadata": {},
   "source": [
    "## Set Up for Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89181d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<pre>Autoreload enabled</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<pre>Project root: /scratch/edk202/word2gm-fast\n",
       "TensorFlow version: 2.19.0\n",
       "Device mode: CPU-only</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<pre>Data preprocessing environment ready!</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set project root directory and add `src` to path\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = '/scratch/edk202/word2gm-fast'\n",
    "project_root = Path(PROJECT_ROOT)\n",
    "src_path = project_root / 'src'\n",
    "\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "\n",
    "# Import the notebook setup utilities\n",
    "from word2gm_fast.utils.notebook_setup import setup_data_preprocessing_notebook, enable_autoreload\n",
    "\n",
    "# Enable autoreload for development\n",
    "enable_autoreload()\n",
    "\n",
    "# Set up environment (CPU-only for data preprocessing)\n",
    "env = setup_data_preprocessing_notebook(project_root=PROJECT_ROOT)\n",
    "\n",
    "# Extract commonly used modules for convenience\n",
    "tf = env['tensorflow']\n",
    "np = env['numpy']\n",
    "pd = env['pandas']\n",
    "batch_prepare_training_data = env['batch_prepare_training_data']\n",
    "print_resource_summary = env['print_resource_summary']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c72a7c6",
   "metadata": {},
   "source": [
    "## Print Resource Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43483cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<pre>SYSTEM RESOURCE SUMMARY\n",
       "============================================================\n",
       "Hostname: gr043.hpc.nyu.edu\n",
       "\n",
       "Job Allocation:\n",
       "   CPUs: 14\n",
       "   Memory: 125.0 GB\n",
       "   Requested partitions: rtx8000,v100,a100_2,a100_1,h100_1\n",
       "   Running on: SSH failed: Host key verification failed.\n",
       "   Job ID: 63296830\n",
       "   Node list: gr043\n",
       "\n",
       "GPU Information:\n",
       "   CUDA GPUs detected: 1\n",
       "   GPU 0: Quadro RTX 8000\n",
       "      Memory: 0.5/45.0 GB (44.5 GB free)\n",
       "      Temperature: 36°C\n",
       "      Utilization: GPU 0%, Memory 0%\n",
       "\n",
       "TensorFlow GPU Detection:\n",
       "   TensorFlow detects 0 GPU(s)\n",
       "   Built with CUDA: True\n",
       "============================================================</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_resource_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36301858",
   "metadata": {},
   "source": [
    "## Prepare Corpora\n",
    "\n",
    "Here, we run the data-preparation pipeline from start to finish — reading preprocessed ngram corpora, generating all valid triplets, extracting the vocabulary, and saving the triplets and vocabulary as `tfrecord` files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14da0c0",
   "metadata": {},
   "source": [
    "### Options for Data Preparation\n",
    "\n",
    "You can control which years are processed and how the batch preparation runs by adjusting the arguments to `batch_prepare_training_data`:\n",
    "\n",
    "**Ways to specify years:**\n",
    "- `year_range=\"2010\"` — Process a single year (e.g., only 2010).\n",
    "- `year_range=\"2010,2012,2015\"` — Process a comma-separated list of years.\n",
    "- `year_range=\"2010-2015\"` — Process a range of years, inclusive (2010 through 2015).\n",
    "- `year_range=\"2010,2012-2014,2016\"` — Combine individual years and ranges (2010, 2012, 2013, 2014, 2016).\n",
    "\n",
    "**Other options:**\n",
    "- `compress` — If `True`, output TFRecords are gzip-compressed. If `False`, output is uncompressed.\n",
    "- `show_progress` — If `True`, display a progress bar for each year.\n",
    "- `show_summary` — If `True`, print a summary of the processed data for each year.\n",
    "- `use_multiprocessing` — If `True`, process years in parallel using multiple CPU cores (recommended for large datasets).\n",
    "\n",
    "See the function docstring or source for more advanced options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e4e2724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "PARALLEL BATCH PROCESSING\n",
      "=================================================================\n",
      "Processing 100 years\n",
      "Using 14 parallel workers\n",
      "Estimated speedup: 14.0x\n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1702 complete (1/100): 63 triplets, 75 vocab, 0.9s\n",
      "1712 complete (2/100): 23 triplets, 36 vocab, 1.0s\n",
      "1713 complete (3/100): 257 triplets, 210 vocab, 1.1s\n",
      "1707 complete (4/100): 117 triplets, 108 vocab, 1.1s\n",
      "1701 complete (5/100): 881 triplets, 542 vocab, 1.5s\n",
      "1706 complete (6/100): 737 triplets, 483 vocab, 1.6s\n",
      "1717 complete (7/100): 314 triplets, 312 vocab, 0.6s\n",
      "1709 complete (8/100): 738 triplets, 465 vocab, 1.7s\n",
      "1708 complete (9/100): 905 triplets, 564 vocab, 1.8s\n",
      "1703 complete (10/100): 1,589 triplets, 794 vocab, 2.2s\n",
      "1718 complete (11/100): 361 triplets, 321 vocab, 1.1s\n",
      "1714 complete (12/100): 1,601 triplets, 834 vocab, 2.3s\n",
      "1715 complete (13/100): 1,497 triplets, 815 vocab, 1.4s\n",
      "1711 complete (14/100): 1,991 triplets, 983 vocab, 2.6s\n",
      "1721 complete (15/100): 1,071 triplets, 644 vocab, 1.2s\n",
      "1705 complete (16/100): 4,010 triplets, 1,568 vocab, 3.5s\n",
      "1716 complete (17/100): 2,749 triplets, 1,110 vocab, 2.5s\n",
      "1704 complete (18/100): 4,645 triplets, 1,738 vocab, 3.6s\n",
      "1725 complete (19/100): 874 triplets, 574 vocab, 1.4s\n",
      "1723 complete (20/100): 1,846 triplets, 912 vocab, 2.2s\n",
      "1729 complete (21/100): 760 triplets, 517 vocab, 1.5s\n",
      "1710 complete (22/100): 5,025 triplets, 1,759 vocab, 4.5s\n",
      "1734 complete (23/100): 183 triplets, 183 vocab, 1.3s\n",
      "1735 complete (24/100): 558 triplets, 346 vocab, 1.2s\n",
      "1731 complete (25/100): 1,002 triplets, 579 vocab, 2.6s\n",
      "1724 complete (26/100): 3,681 triplets, 1,263 vocab, 4.1s\n",
      "1732 complete (27/100): 5,731 triplets, 1,831 vocab, 4.6s\n",
      "1738 complete (28/100): 3,381 triplets, 1,144 vocab, 2.7s\n",
      "1728 complete (29/100): 7,682 triplets, 2,162 vocab, 5.9s\n",
      "1736 complete (30/100): 8,832 triplets, 1,982 vocab, 5.9s\n",
      "1733 complete (31/100): 5,429 triplets, 1,774 vocab, 7.2s\n",
      "1737 complete (32/100): 7,013 triplets, 2,090 vocab, 5.9s\n",
      "1741 complete (33/100): 4,204 triplets, 1,707 vocab, 3.3s\n",
      "1740 complete (34/100): 6,237 triplets, 1,960 vocab, 5.7s\n",
      "1720 complete (35/100): 15,391 triplets, 3,502 vocab, 10.7s\n",
      "1745 complete (36/100): 1,681 triplets, 759 vocab, 1.7s\n",
      "1744 complete (37/100): 3,097 triplets, 1,134 vocab, 2.8s\n",
      "1746 complete (38/100): 3,104 triplets, 1,383 vocab, 4.1s\n",
      "1743 complete (39/100): 10,786 triplets, 2,612 vocab, 8.4s\n",
      "1748 complete (40/100): 5,425 triplets, 1,790 vocab, 5.1s\n",
      "1722 complete (41/100): 30,441 triplets, 3,732 vocab, 20.0s\n",
      "1727 complete (42/100): 31,531 triplets, 4,688 vocab, 19.6s\n",
      "1739 complete (43/100): 24,274 triplets, 4,592 vocab, 16.1s\n",
      "1730 complete (44/100): 32,854 triplets, 3,669 vocab, 20.0s\n",
      "1758 complete (45/100): 2,096 triplets, 1,048 vocab, 2.3s\n",
      "1726 complete (46/100): 42,601 triplets, 5,076 vocab, 25.7s\n",
      "1754 complete (47/100): 14,467 triplets, 3,135 vocab, 11.5s\n",
      "1759 complete (48/100): 8,346 triplets, 2,482 vocab, 5.5s\n",
      "1753 complete (49/100): 15,122 triplets, 3,815 vocab, 15.4s\n",
      "1763 complete (50/100): 6,504 triplets, 2,281 vocab, 4.8s\n",
      "1756 complete (51/100): 18,358 triplets, 3,438 vocab, 15.8s\n",
      "1764 complete (52/100): 1,278 triplets, 824 vocab, 1.2s\n",
      "1761 complete (53/100): 16,291 triplets, 3,781 vocab, 10.5s\n",
      "1757 complete (54/100): 28,042 triplets, 4,407 vocab, 16.9s\n",
      "1762 complete (55/100): 11,687 triplets, 2,916 vocab, 8.8s\n",
      "1750 complete (56/100): 48,012 triplets, 5,143 vocab, 29.0s\n",
      "1719 complete (57/100): 74,493 triplets, 5,166 vocab, 41.5s\n",
      "1751 complete (58/100): 35,349 triplets, 4,859 vocab, 30.9s\n",
      "1755 complete (59/100): 39,664 triplets, 5,530 vocab, 25.1s\n",
      "1752 complete (60/100): 45,301 triplets, 5,344 vocab, 33.0s\n",
      "1760 complete (61/100): 47,081 triplets, 6,001 vocab, 24.7s\n",
      "1768 complete (62/100): 21,822 triplets, 4,031 vocab, 13.6s\n",
      "1769 complete (63/100): 22,304 triplets, 4,352 vocab, 14.2s\n",
      "1766 complete (64/100): 28,167 triplets, 5,071 vocab, 17.0s\n",
      "1772 complete (65/100): 17,806 triplets, 3,497 vocab, 11.6s\n",
      "1767 complete (66/100): 27,680 triplets, 4,727 vocab, 17.4s\n",
      "1776 complete (67/100): 14,314 triplets, 3,204 vocab, 9.1s\n",
      "1778 complete (68/100): 9,327 triplets, 2,576 vocab, 8.0s\n",
      "1770 complete (69/100): 37,272 triplets, 5,371 vocab, 22.2s\n",
      "1774 complete (70/100): 18,838 triplets, 4,021 vocab, 15.9s\n",
      "1777 complete (71/100): 18,248 triplets, 3,866 vocab, 11.4s\n",
      "1765 complete (72/100): 32,542 triplets, 4,607 vocab, 28.6s\n",
      "1773 complete (73/100): 36,340 triplets, 5,310 vocab, 20.2s\n",
      "1742 complete (74/100): 76,210 triplets, 7,023 vocab, 59.5s\n",
      "1781 complete (75/100): 11,419 triplets, 2,893 vocab, 7.5s\n",
      "1771 complete (76/100): 61,047 triplets, 6,870 vocab, 34.2s\n",
      "1779 complete (77/100): 46,199 triplets, 6,182 vocab, 24.0s\n",
      "1785 complete (78/100): 22,116 triplets, 4,123 vocab, 14.8s\n",
      "1749 complete (79/100): 124,675 triplets, 8,615 vocab, 70.0s\n",
      "1787 complete (80/100): 18,145 triplets, 3,960 vocab, 15.8s\n",
      "1788 complete (81/100): 15,871 triplets, 3,734 vocab, 15.5s\n",
      "1786 complete (82/100): 32,815 triplets, 5,328 vocab, 22.6s\n",
      "1783 complete (83/100): 45,028 triplets, 6,081 vocab, 28.0s\n",
      "1780 complete (84/100): 75,241 triplets, 6,528 vocab, 39.7s\n",
      "1789 complete (85/100): 45,703 triplets, 6,024 vocab, 30.4s\n",
      "1775 complete (86/100): 88,412 triplets, 7,257 vocab, 58.6s\n",
      "1791 complete (87/100): 54,951 triplets, 6,618 vocab, 33.4s\n",
      "1792 complete (88/100): 53,184 triplets, 6,490 vocab, 32.6s\n",
      "1795 complete (89/100): 66,004 triplets, 6,749 vocab, 40.5s\n",
      "1747 complete (90/100): 141,201 triplets, 9,033 vocab, 112.9s\n",
      "1782 complete (91/100): 116,146 triplets, 8,921 vocab, 65.0s\n",
      "1793 complete (92/100): 85,769 triplets, 8,536 vocab, 49.2s\n",
      "1799 complete (93/100): 58,770 triplets, 6,807 vocab, 32.4s\n",
      "1798 complete (94/100): 71,944 triplets, 8,242 vocab, 38.7s\n",
      "1797 complete (95/100): 91,994 triplets, 8,249 vocab, 48.9s\n",
      "1790 complete (96/100): 123,008 triplets, 9,234 vocab, 65.5s\n",
      "1784 complete (97/100): 167,569 triplets, 9,936 vocab, 87.3s\n",
      "1794 complete (98/100): 135,171 triplets, 8,723 vocab, 69.8s\n",
      "1796 complete (99/100): 253,557 triplets, 12,886 vocab, 97.4s\n",
      "1800 complete (100/100): 794,296 triplets, 20,685 vocab, 200.5s\n",
      "\n",
      "Parallel processing completed in 312.2s\n",
      "\n",
      "=================================================================\n",
      "Batch processing complete!\n",
      "=================================================================\n",
      "Successful: 100 years\n",
      "   Total triplets: 3,860,368\n",
      "   Average vocab size: 3,818\n",
      "   Average time per year: 20.9s\n",
      "   Overall triplets/second: 12,365\n",
      "   Parallel speedup: 6.7x\n",
      "   Parallel efficiency: 47.7%\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "corpus_dir = \"/vast/edk202/NLP_corpora/Google_Books/20200217/eng-fiction/5gram_files/6corpus/yearly_files/data\"\n",
    "\n",
    "# Process years with multiprocessing (CPU-only mode configured in cell 2)\n",
    "results = batch_prepare_training_data(\n",
    "    corpus_dir=corpus_dir,\n",
    "    year_range=\"1701-1800\",\n",
    "    compress=False,\n",
    "    show_progress=True,\n",
    "    show_summary=True,\n",
    "    use_multiprocessing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8464b3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Remote kernel: word2gm-fast2",
   "language": "python",
   "name": "word2gm-fast2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
