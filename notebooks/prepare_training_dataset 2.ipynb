{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d3ce6ba",
   "metadata": {},
   "source": [
    "# Skip-Gram Data Preparation\n",
    "\n",
    "**Pipeline: Corpus file → TFRecord training artifacts (triplets and vocabulary)**\n",
    "\n",
    "Use this notebook to prepare Google 5gram corpora for skip-gram training.\n",
    "\n",
    "## Pipeline Workflow\n",
    "\n",
    "1. **Input**: Preprocessed corpus file (e.g., `2019.txt`) in `/vast` storage\n",
    "\n",
    "2. **Processing**:\n",
    "    * Convert text corpus to `tf.data.TextLineDataset` object\n",
    "    * Create an in-memory vocab frequency dictionary\n",
    "    * Generate an in-memory `tf.dataset` object containing string triplets; downsample if requested\n",
    "    * Index vocab and convert truplets to integers\n",
    "\n",
    "3. **Output**: TFRecord artifacts in organized subdirectories (e.g., `2019_artifacts/`)\n",
    "\n",
    "### **Artifact Storage**\n",
    "The pipeline creates year-specific subdirectories alongside the original text corpora:\n",
    "<pre>\n",
    "/vast/edk202/NLP_corpora/.../data/\n",
    "├── 2018.txt\n",
    "├── 2019.txt\n",
    "├── 2020.txt\n",
    "├── 2018_artifacts/\n",
    "│   ├── triplets.tfrecord.gz\n",
    "│   └── vocab.tfrecord.gz\n",
    "├── 2019_artifacts/\n",
    "│   ├── triplets.tfrecord.gz\n",
    "│   └── vocab.tfrecord.gz\n",
    "└── 2020_artifacts/\n",
    "    ├── triplets.tfrecord.gz\n",
    "    └── vocab.tfrecord.gz\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d49f604",
   "metadata": {},
   "source": [
    "## Set Up for Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89a7fc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable autoreload for development\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89181d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set project root and add src to path\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "PROJECT_ROOT = '/scratch/edk202/word2gm-fast'\n",
    "project_root = Path(PROJECT_ROOT)\n",
    "src_path = project_root / 'src'\n",
    "\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43483cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1752760209.528197 1953303 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1752760209.533473 1953303 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1752760209.547178 1953303 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752760209.547201 1953303 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752760209.547202 1953303 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752760209.547203 1953303 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<pre>SYSTEM RESOURCE SUMMARY\n",
       "=============================================\n",
       "Hostname: cm046.hpc.nyu.edu\n",
       "\n",
       "Job Allocation:\n",
       "   CPUs: 36\n",
       "   Memory: 250.0 GB\n",
       "   Partition: SSH failed, using fallback: short,cm\n",
       "   Job ID: 63820737\n",
       "   Node list: cm046\n",
       "\n",
       "Physical GPU Hardware:\n",
       "   No physical GPUs allocated to this job\n",
       "\n",
       "TensorFlow GPU Recognition:\n",
       "   TensorFlow can access 0 GPU(s)\n",
       "   Built with CUDA support: True\n",
       "=============================================</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print resource summary\n",
    "from word2gm_fast.utils.resource_summary import print_resource_summary\n",
    "\n",
    "print_resource_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3212d201",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_path = (\n",
    "    '/vast/edk202/NLP_corpora/Google_Books/20200217/eng-fiction/5gram_files/'\n",
    "    '6corpus/yearly_files/data/1778.txt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac1a8716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style='font-family: monospace; font-size: 120%; font-weight: normal;'>\n",
       "Preview of 10 random retained 5-grams:<br><br>&nbsp;&nbsp;&nbsp;   UNK foster parent UNK UNK<br>&nbsp;&nbsp;&nbsp;   UNK old way UNK UNK<br>&nbsp;&nbsp;&nbsp;   UNK free enjoyment UNK UNK<br>&nbsp;&nbsp;&nbsp;   UNK one hand UNK UNK<br>&nbsp;&nbsp;&nbsp;   UNK thus reply UNK UNK<br>&nbsp;&nbsp;&nbsp;   UNK truly great man UNK<br>&nbsp;&nbsp;&nbsp;   UNK man lay dead UNK<br>&nbsp;&nbsp;&nbsp;   UNK neither blind UNK deaf<br>&nbsp;&nbsp;&nbsp;   UNK hundred pound UNK UNK<br>&nbsp;&nbsp;&nbsp;   UNK help thinking UNK UNK<br></span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style='font-family: monospace; font-size: 120%; font-weight: normal;'>\n",
       "Processed Dataset Properties:<br><br>- Element spec: TensorSpec(shape=(), dtype=tf.string, name=None)<br>- Cardinality: Unknown<br>- Threading: Default settings<br>- Transformations: Cached<br></span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style='font-family: monospace; font-size: 120%; font-weight: normal;'>\n",
       "Summary:<br><br>- Retained: 7491<br>- Rejected: 15544<br>- Total: 23035<br></span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from word2gm_fast.dataprep.corpus_to_dataset import make_dataset\n",
    "\n",
    "tf_dataset, _ = make_dataset(\n",
    "    corpus_path,\n",
    "    cache=True,\n",
    "    show_summary=True,\n",
    "    show_properties=True,\n",
    "    preview_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1e5cb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from word2gm_fast.dataprep.dataset_to_frequency import dataset_to_frequency\n",
    "\n",
    "frequency_table = dataset_to_frequency(tf_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecce9d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style='font-family: monospace; font-size: 120%; font-weight: normal;'>\n",
       "Preview of 10 random triplets:<br><br>&nbsp;&nbsp;&nbsp;   (shall, call, execute)<br>&nbsp;&nbsp;&nbsp;   (happiness, secure, foul)<br>&nbsp;&nbsp;&nbsp;   (blind, deaf, observer)<br>&nbsp;&nbsp;&nbsp;   (write, originally, distant)<br>&nbsp;&nbsp;&nbsp;   (deal, agitate, list)<br>&nbsp;&nbsp;&nbsp;   (upon, breast, force)<br>&nbsp;&nbsp;&nbsp;   (accept, invitation, dark)<br>&nbsp;&nbsp;&nbsp;   (london, port, satisfy)<br>&nbsp;&nbsp;&nbsp;   (wound, dress, white)<br>&nbsp;&nbsp;&nbsp;   (treatment, consider, intoxication)<br></span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style='font-family: monospace; font-size: 120%; font-weight: normal;'>\n",
       "Triplets Dataset Properties:<br><br>- Element spec: TensorSpec(shape=(3,), dtype=tf.string, name=None)<br>- Cardinality: Unknown<br>- Threading: Default settings<br>- Transformations: Mapped, FlatMapped, Cached<br></span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style='font-family: monospace; font-size: 120%; font-weight: normal;'>\n",
       "Generated Triplets Summary:<br><br>- Total triplets: 2,284<br>- Unique centers: 1,045<br>- Unique positives: 1,621<br>- Unique negatives: 1,552<br>- Total unique words: 2,354<br></span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from word2gm_fast.dataprep.dataset_to_triplets import dataset_to_triplets\n",
    "\n",
    "triplets_ds, _ = dataset_to_triplets(\n",
    "    dataset=tf_dataset,\n",
    "    frequency_table=frequency_table,\n",
    "    downsample_threshold=1e-5,\n",
    "    preview_n=10,\n",
    "    cache=True,\n",
    "    show_properties=True,\n",
    "    show_summary=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0546c16d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style='font-family: monospace; font-size: 120%; font-weight: normal;'>\n",
       "Preview of 10 random integer triplets:<br><br>&nbsp;&nbsp;&nbsp;   (8, 66, 1799)<br>&nbsp;&nbsp;&nbsp;   (198, 2186, 1842)<br>&nbsp;&nbsp;&nbsp;   (730, 1722, 2035)<br>&nbsp;&nbsp;&nbsp;   (222, 2047, 528)<br>&nbsp;&nbsp;&nbsp;   (117, 861, 1967)<br>&nbsp;&nbsp;&nbsp;   (7, 734, 257)<br>&nbsp;&nbsp;&nbsp;   (232, 970, 164)<br>&nbsp;&nbsp;&nbsp;   (481, 2086, 1038)<br>&nbsp;&nbsp;&nbsp;   (591, 922, 2346)<br>&nbsp;&nbsp;&nbsp;   (1529, 1196, 1933)<br></span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style='font-family: monospace; font-size: 120%; font-weight: normal;'>\n",
       "Integer Triplets Dataset Properties:<br><br>- Element spec: TensorSpec(shape=(3,), dtype=tf.int32, name=None)<br>- Cardinality: 2284<br>- Threading: Default settings<br>- Transformations: TensorSlices, Cached<br></span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style='font-family: monospace; font-size: 120%; font-weight: normal;'>\n",
       "Vocabulary Summary:<br><br>- Vocabulary size: 2,355<br>- Index range: 0 to 2,354<br>- UNK token: UNK (index 0)<br>- Sample tokens: would, one, great, make, good<br></span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from word2gm_fast.dataprep.index_vocab import triplets_to_integers\n",
    "\n",
    "integer_triplets, vocab_table, vocab_list, vocab_size, vocab_summary = triplets_to_integers(\n",
    "    triplets_dataset=triplets_ds,\n",
    "    frequency_table=frequency_table,\n",
    "    preview_n=10,\n",
    "    show_summary=True,\n",
    "    show_properties=True,\n",
    "    cache=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e86ee5fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style='font-family: monospace; font-size: 120%; font-weight: normal;'>Writing vocabulary TFRecord to: /vast/edk202/NLP_corpora/Google_Books/20200217/eng-fiction/5gram_files/6corpus/yearly_files/data/1778_artifacts/vocab.tfrecord</span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style='font-family: monospace; font-size: 120%; font-weight: normal;'>Vocabulary write complete. Words written: 2,355</span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style='font-family: monospace; font-size: 120%; font-weight: normal;'>Writing TFRecord to: /vast/edk202/NLP_corpora/Google_Books/20200217/eng-fiction/5gram_files/6corpus/yearly_files/data/1778_artifacts/triplets.tfrecord</span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style='font-family: monospace; font-size: 120%; font-weight: normal;'>Write complete. Triplets written: 2,284</span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from word2gm_fast.io.vocab import write_vocab_to_tfrecord\n",
    "from word2gm_fast.io.triplets import write_triplets_to_tfrecord\n",
    "import os\n",
    "\n",
    "# Define output directory\n",
    "output_dir = (\n",
    "    '/vast/edk202/NLP_corpora/Google_Books/20200217/eng-fiction/5gram_files/'\n",
    "    '6corpus/yearly_files/data/1778_artifacts'\n",
    ")\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save vocabulary table (compressed)\n",
    "vocab_path = f\"{output_dir}/vocab.tfrecord\"\n",
    "write_vocab_to_tfrecord(\n",
    "    vocab_table=vocab_table,\n",
    "    output_path=vocab_path,\n",
    "    compress=False\n",
    ")\n",
    "\n",
    "# Save integer triplets (compressed)\n",
    "triplets_path = f\"{output_dir}/triplets.tfrecord\"\n",
    "triplet_count = write_triplets_to_tfrecord(\n",
    "    dataset=integer_triplets,\n",
    "    output_path=triplets_path,\n",
    "    compress=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e30343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style='font-family: monospace; font-size: 120%; font-weight: normal;'>Processing 31 years: 1989-2019</span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style='font-family: monospace; font-size: 120%; font-weight: normal;'>Using 32 parallel workers</span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from word2gm_fast.dataprep.pipeline import run_pipeline\n",
    "\n",
    "corpus_dir = '/vast/edk202/NLP_corpora/Google_Books/20200217/eng-fiction/5gram_files/6corpus/yearly_files/data'\n",
    "year_range = \"1989-2019\"\n",
    "\n",
    "results = run_pipeline(\n",
    "    corpus_dir=corpus_dir,\n",
    "    years=year_range,\n",
    "    compress=False,\n",
    "    max_workers=32,\n",
    "    downsample_threshold=1e-5,\n",
    "    cache=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5add22f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Remote kernel: word2gm-fast2",
   "language": "python",
   "name": "word2gm-fast2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
