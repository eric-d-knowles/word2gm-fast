{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d3ce6ba",
   "metadata": {},
   "source": [
    "# Skip-Gram Data Preparation\n",
    "\n",
    "**Pipeline: Corpus file → TFRecord training artifacts (triplets and vocabulary)**\n",
    "\n",
    "Use this notebook to prepare Google 5gram corpora for skip-gram training.\n",
    "\n",
    "## Pipeline Workflow\n",
    "\n",
    "1. **Input**: Preprocessed corpus file (e.g., `2019.txt`) in `/vast` storage\n",
    "\n",
    "2. **Processing**:\n",
    "    * Convert text corpus to `tf.data.TextLineDataset` object\n",
    "    * Creast vocabulary frequency table\n",
    "    * Generate string triplets with optional frequency-based downsampling \n",
    "\n",
    "3. **Output**: TFRecord artifacts in organized subdirectories (e.g., `2019_artifacts/`)\n",
    "\n",
    "### **Artifact Storage**\n",
    "The pipeline creates year-specific subdirectories alongside the original text corpora:\n",
    "<pre>\n",
    "/vast/edk202/NLP_corpora/.../data/\n",
    "├── 2018.txt\n",
    "├── 2019.txt\n",
    "├── 2020.txt\n",
    "├── 2018_artifacts/\n",
    "│   ├── triplets.tfrecord.gz\n",
    "│   └── vocab.tfrecord.gz\n",
    "├── 2019_artifacts/\n",
    "│   ├── triplets.tfrecord.gz\n",
    "│   └── vocab.tfrecord.gz\n",
    "└── 2020_artifacts/\n",
    "    ├── triplets.tfrecord.gz\n",
    "    └── vocab.tfrecord.gz\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d49f604",
   "metadata": {},
   "source": [
    "## Set Up for Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89a7fc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable autoreload for development\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89181d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set project root and add src to path\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "PROJECT_ROOT = '/scratch/edk202/word2gm-fast'\n",
    "project_root = Path(PROJECT_ROOT)\n",
    "src_path = project_root / 'src'\n",
    "\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43483cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1752596173.367734 3611430 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1752596173.372955 3611430 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1752596173.386267 3611430 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752596173.386281 3611430 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752596173.386282 3611430 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752596173.386284 3611430 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<pre>SYSTEM RESOURCE SUMMARY\n",
       "=============================================\n",
       "Hostname: cm050.hpc.nyu.edu\n",
       "\n",
       "Job Allocation:\n",
       "   CPUs: 14\n",
       "   Memory: 125.0 GB\n",
       "   Partition: short\n",
       "   Job ID: 63744123\n",
       "   Node list: cm050\n",
       "\n",
       "Physical GPU Hardware:\n",
       "   No physical GPUs allocated to this job\n",
       "\n",
       "TensorFlow GPU Recognition:\n",
       "   TensorFlow can access 0 GPU(s)\n",
       "   Built with CUDA support: True\n",
       "=============================================</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print resource summary\n",
    "from word2gm_fast.utils.resource_summary import print_resource_summary\n",
    "\n",
    "print_resource_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3212d201",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_path = (\n",
    "    '/vast/edk202/NLP_corpora/Google_Books/20200217/eng-fiction/5gram_files/'\n",
    "    '6corpus/yearly_files/data/1631.txt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac1a8716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style='font-family: monospace; font-size: 120%; font-weight: normal;'>\n",
       "Preview of 10 random retained 5-grams:<br><br>&nbsp;&nbsp;&nbsp;   UNK UNK spanish dominion UNK<br>&nbsp;&nbsp;&nbsp;   UNK UNK midst UNK war<br>&nbsp;&nbsp;&nbsp;   cut UNK notch UNK UNK<br>&nbsp;&nbsp;&nbsp;   take UNK sea UNK UNK<br>&nbsp;&nbsp;&nbsp;   UNK convenient place UNK UNK<br>&nbsp;&nbsp;&nbsp;   UNK know well UNK UNK<br>&nbsp;&nbsp;&nbsp;   UNK UNK much facility UNK<br>&nbsp;&nbsp;&nbsp;   build UNK one day UNK<br>&nbsp;&nbsp;&nbsp;   upon UNK guard UNK UNK<br>&nbsp;&nbsp;&nbsp;   UNK UNK neither know UNK<br></span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style='font-family: monospace; font-size: 120%; font-weight: normal;'>\n",
       "Processed Dataset Properties:<br><br>- Element spec: TensorSpec(shape=(), dtype=tf.string, name=None)<br>- Cardinality: Unknown<br>- Threading: Default settings<br>- Transformations: Cached<br></span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style='font-family: monospace; font-size: 120%; font-weight: normal;'>\n",
       "Summary:<br><br>- Retained: 215<br>- Rejected: 590<br>- Total: 805<br></span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from word2gm_fast.dataprep.corpus_to_dataset import make_dataset\n",
    "\n",
    "tf_dataset, _ = make_dataset(\n",
    "    corpus_path,\n",
    "    cache=True,\n",
    "    show_summary=True,\n",
    "    show_properties=True,\n",
    "    preview_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1e5cb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from word2gm_fast.dataprep.dataset_to_frequency import dataset_to_frequency\n",
    "\n",
    "frequency_table = dataset_to_frequency(tf_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0bf2d8fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style='font-family: monospace; font-size: 120%; font-weight: normal;'>\n",
       "Preview of 10 random triplets:<br><br>&nbsp;&nbsp;&nbsp;   (tell, well, devise)<br>&nbsp;&nbsp;&nbsp;   (child, woman, dominion)<br>&nbsp;&nbsp;&nbsp;   (would, indeed, matter)<br>&nbsp;&nbsp;&nbsp;   (hundred, pound, religion)<br>&nbsp;&nbsp;&nbsp;   (great, river, body)<br>&nbsp;&nbsp;&nbsp;   (place, call, possibly)<br>&nbsp;&nbsp;&nbsp;   (question, great, truth)<br>&nbsp;&nbsp;&nbsp;   (bad, bad, nobleman)<br>&nbsp;&nbsp;&nbsp;   (great, toe, furnish)<br>&nbsp;&nbsp;&nbsp;   (west, east, pound)<br></span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style='font-family: monospace; font-size: 120%; font-weight: normal;'>\n",
       "Triplets Dataset Properties:<br><br>- Element spec: TensorSpec(shape=(3,), dtype=tf.string, name=None)<br>- Cardinality: Unknown<br>- Threading: Default settings<br>- Transformations: Mapped, FlatMapped, Cached<br></span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style='font-family: monospace; font-size: 120%; font-weight: normal;'>\n",
       "Generated Triplets Summary:<br><br>- Total triplets: 21<br>- Unique centers: 20<br>- Unique positives: 21<br>- Unique negatives: 21<br>- Total unique words: 58<br></span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from word2gm_fast.dataprep.dataset_to_triplets import dataset_to_triplets\n",
    "\n",
    "triplets_ds, _ = dataset_to_triplets(\n",
    "    dataset=tf_dataset,\n",
    "    frequency_table=frequency_table,\n",
    "    downsample_threshold=1e-5,\n",
    "    preview_n=10,\n",
    "    cache=True,\n",
    "    show_properties=True,\n",
    "    show_summary=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ecce9d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style='font-family: monospace; font-size: 120%; font-weight: normal;'>\n",
       "Preview of 5 random triplets:<br><br>&nbsp;&nbsp;&nbsp;   (good, use, none)<br>&nbsp;&nbsp;&nbsp;   (great, river, body)<br>&nbsp;&nbsp;&nbsp;   (french, spaniard, tall)<br>&nbsp;&nbsp;&nbsp;   (child, woman, dominion)<br>&nbsp;&nbsp;&nbsp;   (away, run, charity)<br></span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style='font-family: monospace; font-size: 120%; font-weight: normal;'>\n",
       "Triplets Dataset Properties:<br><br>- Element spec: TensorSpec(shape=(3,), dtype=tf.string, name=None)<br>- Cardinality: Unknown<br>- Threading: Default settings<br>- Transformations: Mapped, FlatMapped, Cached<br></span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style='font-family: monospace; font-size: 120%; font-weight: normal;'>\n",
       "Generated Triplets Summary:<br><br>- Total triplets: 21<br>- Unique centers: 20<br>- Unique positives: 21<br>- Unique negatives: 21<br>- Total unique words: 58<br></span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from word2gm_fast.dataprep.dataset_to_triplets import dataset_to_triplets\n",
    "\n",
    "triplets_ds, _ = dataset_to_triplets(\n",
    "    dataset=tf_dataset,\n",
    "    frequency_table=frequency_table,\n",
    "    downsample_threshold=1e-5,\n",
    "    preview_n=5,\n",
    "    cache=True,\n",
    "    show_properties=True,\n",
    "    show_summary=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0546c16d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style='font-family: monospace; font-size: 120%; font-weight: normal;'>\n",
       "Preview of 10 random integer triplets:<br><br>&nbsp;&nbsp;&nbsp;   (54, 35, 17)<br>&nbsp;&nbsp;&nbsp;   (5, 57, 41)<br>&nbsp;&nbsp;&nbsp;   (24, 53, 55)<br>&nbsp;&nbsp;&nbsp;   (26, 27, 42)<br>&nbsp;&nbsp;&nbsp;   (12, 14, 25)<br>&nbsp;&nbsp;&nbsp;   (10, 40, 45)<br>&nbsp;&nbsp;&nbsp;   (6, 28, 52)<br>&nbsp;&nbsp;&nbsp;   (50, 5, 58)<br>&nbsp;&nbsp;&nbsp;   (5, 29, 33)<br>&nbsp;&nbsp;&nbsp;   (13, 21, 49)<br></span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style='font-family: monospace; font-size: 120%; font-weight: normal;'>\n",
       "Integer Triplets Dataset Properties:<br><br>- Element spec: TensorSpec(shape=(3,), dtype=tf.int32, name=None)<br>- Cardinality: 21<br>- Threading: Default settings<br>- Transformations: TensorSlices, Cached<br></span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style='font-family: monospace; font-size: 120%; font-weight: normal;'>\n",
       "Vocabulary Summary:<br><br>- Vocabulary size: 59<br>- Index range: 0 to 58<br>- UNK token: UNK (index 0)<br>- Sample tokens: hundred, good, pound, two, great<br>- Total token instances: 1,075<br>- Most frequent: UNK(594), hundred(20), good(15), pound(11), two(11)<br></span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from word2gm_fast.dataprep.index_vocab import triplets_to_integers\n",
    "\n",
    "integer_triplets, vocab_table, vocab_list, vocab_size, vocab_summary = triplets_to_integers(\n",
    "    triplets_dataset=triplets_ds,\n",
    "    frequency_table=frequency_table,\n",
    "    preview_n=10,\n",
    "    show_summary=True,\n",
    "    show_properties=True,\n",
    "    cache=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "52aa1053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UNK',\n",
       " 'hundred',\n",
       " 'good',\n",
       " 'pound',\n",
       " 'two',\n",
       " 'great',\n",
       " 'part',\n",
       " 'one',\n",
       " 'well',\n",
       " 'could',\n",
       " 'much',\n",
       " 'west',\n",
       " 'coast',\n",
       " 'place',\n",
       " 'upon',\n",
       " 'would',\n",
       " 'away',\n",
       " 'thing',\n",
       " 'woman',\n",
       " 'another',\n",
       " 'bad',\n",
       " 'call',\n",
       " 'child',\n",
       " 'ever',\n",
       " 'french',\n",
       " 'manner',\n",
       " 'north',\n",
       " 'pole',\n",
       " 'remote',\n",
       " 'river',\n",
       " 'run',\n",
       " 'use',\n",
       " 'want',\n",
       " 'body',\n",
       " 'charity',\n",
       " 'continue',\n",
       " 'devise',\n",
       " 'dominion',\n",
       " 'east',\n",
       " 'except',\n",
       " 'facility',\n",
       " 'furnish',\n",
       " 'glory',\n",
       " 'heires',\n",
       " 'indeed',\n",
       " 'man',\n",
       " 'matter',\n",
       " 'nobleman',\n",
       " 'none',\n",
       " 'possibly',\n",
       " 'question',\n",
       " 'religion',\n",
       " 'rest',\n",
       " 'spaniard',\n",
       " 'story',\n",
       " 'tall',\n",
       " 'tell',\n",
       " 'toe',\n",
       " 'truth']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9c0416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab table type: <class 'tensorflow.python.ops.lookup_ops.StaticHashTable'>\n",
      "Vocab table: <tensorflow.python.ops.lookup_ops.StaticHashTable object at 0x14a22c1252b0>\n",
      "\n",
      "Testing lookup functionality:\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[53]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(vocab_table, \u001b[33m'\u001b[39m\u001b[33mlookup\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m      7\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTesting lookup functionality:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mUNK\u001b[39m\u001b[33m'\u001b[39m\u001b[33m ->\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mvocab_table\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlookup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mUNK\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m      9\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mhundred\u001b[39m\u001b[33m'\u001b[39m\u001b[33m ->\u001b[39m\u001b[33m\"\u001b[39m, vocab_table.lookup([\u001b[33m'\u001b[39m\u001b[33mhundred\u001b[39m\u001b[33m'\u001b[39m]))\n\u001b[32m     10\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mgood\u001b[39m\u001b[33m'\u001b[39m\u001b[33m ->\u001b[39m\u001b[33m\"\u001b[39m, vocab_table.lookup([\u001b[33m'\u001b[39m\u001b[33mgood\u001b[39m\u001b[33m'\u001b[39m]))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ext3/miniforge3/envs/word2gm-fast2/lib/python3.12/site-packages/tensorflow/python/ops/lookup_ops.py:252\u001b[39m, in \u001b[36mInitializableLookupTableBase.lookup\u001b[39m\u001b[34m(self, keys, name)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(keys, (sparse_tensor.SparseTensor, internal.RaggedTensor)):\n\u001b[32m    250\u001b[39m   key_tensor = keys.values\n\u001b[32m--> \u001b[39m\u001b[32m252\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mkeys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m.base_dtype != \u001b[38;5;28mself\u001b[39m._key_dtype:\n\u001b[32m    253\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDtype of argument `keys` must be \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._key_dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    254\u001b[39m                   \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mreceived: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkeys.dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    256\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ops.name_scope(\n\u001b[32m    257\u001b[39m     name, \u001b[33m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m_Lookup\u001b[39m\u001b[33m\"\u001b[39m % \u001b[38;5;28mself\u001b[39m.name,\n\u001b[32m    258\u001b[39m     (\u001b[38;5;28mself\u001b[39m.resource_handle, key_tensor, \u001b[38;5;28mself\u001b[39m._default_value)):\n",
      "\u001b[31mAttributeError\u001b[39m: 'list' object has no attribute 'dtype'"
     ]
    }
   ],
   "source": [
    "# Check vocab_table object type and structure\n",
    "print(\"Vocab table type:\", type(vocab_table))\n",
    "\n",
    "# Import tf to test lookup properly\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check if it has lookup methods\n",
    "if hasattr(vocab_table, 'lookup'):\n",
    "    print(\"\\nTesting lookup functionality:\")\n",
    "    print(\"'UNK' ->\", vocab_table.lookup(tf.constant(['UNK'])).numpy())\n",
    "    print(\"'hundred' ->\", vocab_table.lookup(tf.constant(['hundred'])).numpy())\n",
    "    print(\"'good' ->\", vocab_table.lookup(tf.constant(['good'])).numpy())\n",
    "\n",
    "# Check vocab_table properties\n",
    "print(f\"\\nVocab table key dtype: {vocab_table.key_dtype}\")\n",
    "print(f\"Vocab table value dtype: {vocab_table.value_dtype}\")\n",
    "\n",
    "# Create a simple word-to-index dictionary from vocab_list\n",
    "word_to_index = {word: idx for idx, word in enumerate(vocab_list)}\n",
    "print(f\"\\nCreated word_to_index dictionary with {len(word_to_index)} entries\")\n",
    "print(\"Sample mappings:\")\n",
    "for i, word in enumerate(vocab_list[:5]):\n",
    "    print(f\"  '{word}' -> {word_to_index[word]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Remote kernel: word2gm-fast2",
   "language": "python",
   "name": "word2gm-fast2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
