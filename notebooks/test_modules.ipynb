{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "180684c5",
   "metadata": {},
   "source": [
    "# Test Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27f7e6dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<pre>Autoreload enabled</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<pre>Project root: /scratch/edk202/word2gm-fast\n",
       "TensorFlow version: 2.19.0\n",
       "Device mode: GPU-enabled</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<pre>Testing environment ready!</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set project root directory and add `src` to path\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = '/scratch/edk202/word2gm-fast'\n",
    "project_root = Path(PROJECT_ROOT)\n",
    "src_path = project_root / 'src'\n",
    "\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "\n",
    "# Import the notebook setup utilities\n",
    "from word2gm_fast.utils.notebook_setup import setup_testing_notebook, enable_autoreload, run_silent_subprocess\n",
    "\n",
    "# Enable autoreload for development\n",
    "enable_autoreload()\n",
    "\n",
    "# Set up environment\n",
    "env = setup_testing_notebook(project_root=PROJECT_ROOT)\n",
    "\n",
    "# Extract commonly used modules for convenience\n",
    "tf = env['tensorflow']\n",
    "np = env['numpy']\n",
    "pd = env['pandas']\n",
    "print_resource_summary = env['print_resource_summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51550892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<pre>SYSTEM RESOURCE SUMMARY\n",
       "============================================================\n",
       "Hostname: cm045.hpc.nyu.edu\n",
       "\n",
       "Job Allocation:\n",
       "   CPUs: 28\n",
       "   Memory: 250.0 GB\n",
       "   Requested partitions: short,cm,cpu_a100_2\n",
       "   Actually running on: short\n",
       "   Job ID: 62870003\n",
       "   Node list: cm045\n",
       "\n",
       "GPU Information:\n",
       "   Error: NVML Shared Library Not Found\n",
       "\n",
       "TensorFlow GPU Detection:\n",
       "   TensorFlow detects N/A GPU(s)\n",
       "   Built with CUDA: True\n",
       "============================================================</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_resource_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a48ee228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<pre>[PASS] [TEST -- corpus_to_dataset] test_corpus_to_dataset: Only valid 5-grams kept (center word and at least one context word not UNK); correct summary stats</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<pre>[PASS] [TEST -- dataset_to_triplets] test_center_word_extraction: Center words match expected values\n",
       "[PASS] [TEST -- dataset_to_triplets] test_context_word_extraction: Positive context tokens are valid\n",
       "[PASS] [TEST -- dataset_to_triplets] test_multiple_triplets_per_line: Multiple triplets are generated per line, skipping UNK contexts\n",
       "[PASS] [TEST -- dataset_to_triplets] test_negative_sampling_range: Negative samples are in the correct range and not UNK\n",
       "[PASS] [TEST -- dataset_to_triplets] test_no_triplets_with_unk_context: No triplet has UNK as positive context word</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<pre>[PASS] [TEST -- index_vocab] test_vocab_table_contents: Table contains all expected tokens and handles OOV as UNK</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<pre>[PASS] [TEST -- tfrecord_io] test_write_and_load_triplets_compressed: Roundtrip TFRecord I/O for triplets (compressed)\n",
       "[PASS] [TEST -- tfrecord_io] test_parse_triplet_example: Correct parsing of serialized triplet examples\n",
       "[PASS] [TEST -- tfrecord_io] test_write_and_load_vocab_uncompressed: Roundtrip TFRecord I/O for vocabulary (uncompressed)\n",
       "[PASS] [TEST -- tfrecord_io] test_write_and_load_vocab_compressed: Roundtrip TFRecord I/O for vocabulary (compressed)\n",
       "[PASS] [TEST -- tfrecord_io] test_parse_vocab_example: Correct parsing of serialized vocabulary examples\n",
       "[PASS] [TEST -- tfrecord_io] test_save_and_load_pipeline_artifacts: Saving and loading of all pipeline artifacts (vocab and triplets) as TFRecords</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<pre>[PASS] [TEST -- word2gm_model] test_model_configurations: Model runs with spherical=False, wout=True, num_mixtures=1\n",
       "[PASS] [TEST -- word2gm_model] test_model_configurations: Model runs with spherical=True, wout=False, num_mixtures=1\n",
       "[PASS] [TEST -- word2gm_model] test_model_configurations: Model runs with spherical=False, wout=False, num_mixtures=1\n",
       "[PASS] [TEST -- word2gm_model] test_model_configurations: Model runs with spherical=True, wout=True, num_mixtures=2\n",
       "[PASS] [TEST -- word2gm_model] test_model_configurations: Model runs with spherical=False, wout=True, num_mixtures=2\n",
       "[PASS] [TEST -- word2gm_model] test_model_configurations: Model runs with spherical=True, wout=False, num_mixtures=2\n",
       "[PASS] [TEST -- word2gm_model] test_model_configurations: Model runs with spherical=False, wout=False, num_mixtures=2\n",
       "[PASS] [TEST -- word2gm_model] test_model_configurations: Model runs with spherical=True, wout=True, num_mixtures=3\n",
       "[PASS] [TEST -- word2gm_model] test_model_configurations: Model runs with spherical=False, wout=True, num_mixtures=3\n",
       "[PASS] [TEST -- word2gm_model] test_model_configurations: Model runs with spherical=True, wout=False, num_mixtures=3\n",
       "[PASS] [TEST -- word2gm_model] test_model_configurations: Model runs with spherical=False, wout=False, num_mixtures=3</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime\n",
    "from IPython.display import display, Markdown\n",
    "from collections import OrderedDict\n",
    "\n",
    "modules_to_test = [\n",
    "    ('tests/test_corpus_to_dataset.py', 'Corpus processing'),\n",
    "    ('tests/test_dataset_to_triplets.py', 'Triplet generation'),\n",
    "    ('tests/test_index_vocab.py', 'Vocabulary indexing'), \n",
    "    ('tests/test_tfrecord_io.py', 'TFRecord I/O'),\n",
    "    ('tests/test_word2gm_model.py', 'Word2GM model')\n",
    "]\n",
    "\n",
    "# Group tests by group label, preserving order\n",
    "grouped = OrderedDict()\n",
    "for test_file, group in modules_to_test:\n",
    "    grouped.setdefault(group, []).append(test_file)\n",
    "\n",
    "failures = []\n",
    "\n",
    "for idx, (group, test_files) in enumerate(grouped.items()):\n",
    "    group_summaries = []\n",
    "    for test_file in test_files:\n",
    "        cmd_result = run_silent_subprocess(\n",
    "            ['pytest', test_file, '--maxfail=1', '--disable-warnings', '-q', '-s'],\n",
    "            capture_output=True, text=True\n",
    "        )\n",
    "        status = \"PASS\" if cmd_result.returncode == 0 else \"FAIL\"\n",
    "        summary_lines = []\n",
    "        if cmd_result.stdout:\n",
    "            for line in cmd_result.stdout.splitlines():\n",
    "                line = line.strip()\n",
    "                if line.startswith(\"[TEST\"):\n",
    "                    summary_lines.append(f\"[{status}] {line}\")\n",
    "        if summary_lines:\n",
    "            group_summaries.extend(summary_lines)\n",
    "        else:\n",
    "            display(Markdown(f\"[{status}] No [TEST ...] summary lines found for {test_file}. Raw output:\"))\n",
    "            if cmd_result.stdout:\n",
    "                display(Markdown(f\"<pre>{cmd_result.stdout}</pre>\"))\n",
    "            if cmd_result.stderr:\n",
    "                display(Markdown(f\"<pre>{cmd_result.stderr}</pre>\"))\n",
    "        if cmd_result.returncode != 0:\n",
    "            failures.append((group, cmd_result))\n",
    "    if group_summaries:\n",
    "        display(Markdown(f\"<pre>{chr(10).join(group_summaries)}</pre>\"))\n",
    "\n",
    "if failures:\n",
    "    print(\"\\nDetailed output for failed tests:\")\n",
    "    for group, cmd_result in failures:\n",
    "        print(f\"\\n--- {group} ---\")\n",
    "        if cmd_result.stdout:\n",
    "            print(\"stdout:\\n\" + cmd_result.stdout)\n",
    "        if cmd_result.stderr:\n",
    "            print(\"stderr:\\n\" + cmd_result.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3512f87c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Remote kernel: word2gm-fast2",
   "language": "python",
   "name": "word2gm-fast2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
