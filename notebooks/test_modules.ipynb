{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27f7e6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-05 17:55:22.770446: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-05 17:55:24.301020: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751752524.474937 1472669 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751752524.557421 1472669 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1751752525.071959 1472669 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751752525.071984 1472669 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751752525.071986 1472669 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751752525.071987 1472669 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-05 17:55:25.081292: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<pre>Autoreload enabled</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<pre>Project root: /scratch/edk202/word2gm-fast\n",
       "TensorFlow version: 2.19.0\n",
       "Device mode: GPU-enabled</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<pre>Testing environment ready!</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set project root directory and add `src` to path\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = '/scratch/edk202/word2gm-fast'\n",
    "project_root = Path(PROJECT_ROOT)\n",
    "src_path = project_root / 'src'\n",
    " \n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "\n",
    "# Import the notebook setup utilities\n",
    "from word2gm_fast.utils.notebook_setup import setup_testing_notebook, enable_autoreload, run_silent_subprocess\n",
    "\n",
    "# Enable mixed precision for GPU training\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# Enable autoreload for development\n",
    "enable_autoreload()\n",
    "\n",
    "# Set up environment\n",
    "env = setup_testing_notebook(project_root=PROJECT_ROOT)\n",
    "\n",
    "# Extract commonly used modules for convenience\n",
    "tf = env['tensorflow']\n",
    "np = env['numpy']\n",
    "pd = env['pandas']\n",
    "print_resource_summary = env['print_resource_summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51550892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<pre>SYSTEM RESOURCE SUMMARY\n",
       "============================================================\n",
       "Hostname: cm001.hpc.nyu.edu\n",
       "\n",
       "Job Allocation:\n",
       "   CPUs: 4\n",
       "   Memory: 15.6 GB\n",
       "   Requested partitions: short\n",
       "   Running on: SSH failed: Host key verification failed.\n",
       "   Job ID: 63409877\n",
       "   Node list: cm001\n",
       "\n",
       "GPU Information:\n",
       "   Error: NVML Shared Library Not Found\n",
       "\n",
       "TensorFlow GPU Detection:\n",
       "   TensorFlow detects 0 GPU(s)\n",
       "   Built with CUDA: True\n",
       "============================================================</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_resource_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a48ee228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /scratch/edk202/word2gm-fast\n",
      "Tests directory: /scratch/edk202/word2gm-fast/tests\n",
      "Tests directory exists: True\n",
      "Found 14 test files:\n",
      "  I/O Modules: ['test_index_vocab.py', 'test_artifacts.py', 'test_triplets.py', 'test_tables.py', 'test_vocab.py', 'test_dataset_to_triplets.py']\n",
      "  Corpus Processing Modules: ['test_index_vocab.py', 'test_corpus_to_dataset.py', 'test_dataset_to_triplets.py']\n",
      "  Integration Tests: ['test_pipeline.py', 'test_io_integration.py']\n",
      "  Model Training Modules: ['test_notebook_training.py', 'test_word2gm_model.py', 'test_training_utils.py', 'test_train_loop.py', 'test_resource_monitor.py']\n",
      "\n",
      "Import verification...\n",
      "SUCCESS: All modules imported successfully\n",
      "\n",
      "================================================================================\n",
      "RUNNING ALL TESTS\n",
      "================================================================================\n",
      "STDOUT:\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.12.11, pytest-8.4.1, pluggy-1.6.0 -- /ext3/miniforge3/envs/word2gm-fast2/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /scratch/edk202/word2gm-fast\n",
      "plugins: anyio-4.9.0, timeout-2.4.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 92 items\n",
      "\n",
      "tests/test_artifacts.py::TestArtifactsModule::test_save_metadata_uncompressed \u001b[32mPASSED\u001b[0m\u001b[32m [  1%]\u001b[0m\n",
      "tests/test_artifacts.py::TestArtifactsModule::test_save_metadata_compressed \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "tests/test_artifacts.py::TestArtifactsModule::test_load_metadata_uncompressed \u001b[32mPASSED\u001b[0m\u001b[32m [  3%]\u001b[0m\n",
      "tests/test_artifacts.py::TestArtifactsModule::test_load_metadata_compressed \u001b[32mPASSED\u001b[0m\u001b[32m [  4%]\u001b[0m\n",
      "tests/test_artifacts.py::TestArtifactsModule::test_metadata_roundtrip \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
      "tests/test_artifacts.py::TestArtifactsModule::test_save_pipeline_artifacts \u001b[32mPASSED\u001b[0m\u001b[32m [  6%]\u001b[0m\n",
      "tests/test_artifacts.py::TestArtifactsModule::test_load_pipeline_artifacts \u001b[32mPASSED\u001b[0m\u001b[32m [  7%]\u001b[0m\n",
      "tests/test_artifacts.py::TestArtifactsModule::test_pipeline_artifacts_roundtrip \u001b[32mPASSED\u001b[0m\u001b[32m [  8%]\u001b[0m\n",
      "tests/test_artifacts.py::TestArtifactsModule::test_empty_metadata \u001b[32mPASSED\u001b[0m\u001b[32m [  9%]\u001b[0m\n",
      "tests/test_artifacts.py::TestArtifactsModule::test_large_metadata \u001b[32mPASSED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
      "tests/test_corpus_to_dataset.py::test_corpus_to_dataset \u001b[32mPASSED\u001b[0m\u001b[32m           [ 11%]\u001b[0m\n",
      "tests/test_dataset_to_triplets.py::test_basic_triplet_generation \u001b[32mPASSED\u001b[0m\u001b[32m  [ 13%]\u001b[0m\n",
      "tests/test_dataset_to_triplets.py::test_center_word_extraction \u001b[32mPASSED\u001b[0m\u001b[32m    [ 14%]\u001b[0m\n",
      "tests/test_dataset_to_triplets.py::test_context_word_extraction \u001b[32mPASSED\u001b[0m\u001b[32m   [ 15%]\u001b[0m\n",
      "tests/test_dataset_to_triplets.py::test_multiple_triplets_per_line \u001b[32mPASSED\u001b[0m\u001b[32m [ 16%]\u001b[0m\n",
      "tests/test_dataset_to_triplets.py::test_negative_sampling_range \u001b[32mPASSED\u001b[0m\u001b[32m   [ 17%]\u001b[0m\n",
      "tests/test_dataset_to_triplets.py::test_no_triplets_with_unk_context \u001b[32mPASSED\u001b[0m\u001b[32m [ 18%]\u001b[0m\n",
      "tests/test_dataset_to_triplets.py::test_frequency_based_downsampling \u001b[32mPASSED\u001b[0m\u001b[32m [ 19%]\u001b[0m\n",
      "tests/test_dataset_to_triplets.py::test_downsampling_threshold_effect \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
      "tests/test_dataset_to_triplets.py::test_frequencies_none_no_downsampling \u001b[32mPASSED\u001b[0m\u001b[32m [ 21%]\u001b[0m\n",
      "tests/test_index_vocab.py::test_make_vocab_table \u001b[32mPASSED\u001b[0m\u001b[32m                  [ 22%]\u001b[0m\n",
      "tests/test_index_vocab.py::test_vocab_table_contents \u001b[32mPASSED\u001b[0m\u001b[32m              [ 23%]\u001b[0m\n",
      "tests/test_index_vocab.py::test_word_index_roundtrip \u001b[32mPASSED\u001b[0m\u001b[32m              [ 25%]\u001b[0m\n",
      "tests/test_io_integration.py::test_vocab_tables_roundtrip_consistency \u001b[32mPASSED\u001b[0m\u001b[32m [ 26%]\u001b[0m\n",
      "tests/test_io_integration.py::test_frequency_preservation_through_pipeline \u001b[32mPASSED\u001b[0m\u001b[32m [ 27%]\u001b[0m\n",
      "tests/test_io_integration.py::test_complete_artifacts_pipeline \u001b[32mPASSED\u001b[0m\u001b[32m    [ 28%]\u001b[0m\n",
      "tests/test_io_integration.py::test_artifacts_compression_consistency \u001b[32mPASSED\u001b[0m\u001b[32m [ 29%]\u001b[0m\n",
      "tests/test_io_integration.py::test_artifacts_auto_detection \u001b[32mPASSED\u001b[0m\u001b[32m       [ 30%]\u001b[0m\n",
      "tests/test_io_integration.py::test_error_handling_missing_files \u001b[32mPASSED\u001b[0m\u001b[32m   [ 31%]\u001b[0m\n",
      "tests/test_notebook_training.py::test_run_notebook_training_runs \u001b[32mPASSED\u001b[0m\u001b[32m  [ 32%]\u001b[0m\n",
      "tests/test_pipeline.py::test_get_corpus_years \u001b[32mPASSED\u001b[0m\u001b[32m                     [ 33%]\u001b[0m\n",
      "tests/test_pipeline.py::test_get_corpus_years_empty_directory \u001b[32mPASSED\u001b[0m\u001b[32m     [ 34%]\u001b[0m\n",
      "tests/test_pipeline.py::test_get_corpus_years_nonexistent_directory \u001b[32mPASSED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
      "tests/test_pipeline.py::test_parse_year_range \u001b[32mPASSED\u001b[0m\u001b[32m                     [ 36%]\u001b[0m\n",
      "tests/test_pipeline.py::test_parse_year_range_invalid \u001b[32mPASSED\u001b[0m\u001b[32m             [ 38%]\u001b[0m\n",
      "tests/test_pipeline.py::test_prepare_training_data_success \u001b[32mPASSED\u001b[0m\u001b[32m        [ 39%]\u001b[0m\n",
      "tests/test_pipeline.py::test_prepare_training_data_file_not_found \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
      "tests/test_pipeline.py::test_prepare_training_data_invalid_directory \u001b[32mPASSED\u001b[0m\u001b[32m [ 41%]\u001b[0m\n",
      "tests/test_pipeline.py::test_batch_prepare_training_data_auto_discovery \u001b[32mPASSED\u001b[0m\u001b[32m [ 42%]\u001b[0m\n",
      "tests/test_pipeline.py::test_batch_prepare_training_data_specific_years \u001b[32mPASSED\u001b[0m\u001b[32m [ 43%]\u001b[0m\n",
      "tests/test_pipeline.py::test_batch_prepare_training_data_year_range \u001b[32mPASSED\u001b[0m\u001b[32m [ 44%]\u001b[0m\n",
      "tests/test_pipeline.py::test_batch_prepare_training_data_conflicting_params \u001b[32mPASSED\u001b[0m\u001b[32m [ 45%]\u001b[0m\n",
      "tests/test_pipeline.py::test_batch_prepare_training_data_missing_files \u001b[32mPASSED\u001b[0m\u001b[32m [ 46%]\u001b[0m\n",
      "tests/test_pipeline.py::test_detect_cluster_resources \u001b[32mPASSED\u001b[0m\u001b[32m             [ 47%]\u001b[0m\n",
      "tests/test_pipeline.py::test_detect_cluster_resources_slurm \u001b[32mPASSED\u001b[0m\u001b[32m       [ 48%]\u001b[0m\n",
      "tests/test_pipeline.py::test_get_safe_worker_count \u001b[32mPASSED\u001b[0m\u001b[32m                [ 50%]\u001b[0m\n",
      "tests/test_pipeline.py::test_process_single_year_helper \u001b[32mPASSED\u001b[0m\u001b[32m           [ 51%]\u001b[0m\n",
      "tests/test_pipeline.py::test_process_single_year_helper_error \u001b[32mPASSED\u001b[0m\u001b[32m     [ 52%]\u001b[0m\n",
      "tests/test_resource_monitor.py::test_resource_monitor_basic \u001b[32mPASSED\u001b[0m\u001b[32m       [ 53%]\u001b[0m\n",
      "tests/test_resource_monitor.py::test_resource_monitor_tensorboard \u001b[32mPASSED\u001b[0m\u001b[32m [ 54%]\u001b[0m\n",
      "tests/test_tables.py::TestTablesModule::test_create_token_to_index_table \u001b[32mPASSED\u001b[0m\u001b[32m [ 55%]\u001b[0m\n",
      "tests/test_tables.py::TestTablesModule::test_create_index_to_token_table \u001b[32mPASSED\u001b[0m\u001b[32m [ 56%]\u001b[0m\n",
      "tests/test_tables.py::TestTablesModule::test_token_to_index_default_value \u001b[32mPASSED\u001b[0m\u001b[32m [ 57%]\u001b[0m\n",
      "tests/test_tables.py::TestTablesModule::test_index_to_token_default_value \u001b[32mPASSED\u001b[0m\u001b[32m [ 58%]\u001b[0m\n",
      "tests/test_tables.py::TestTablesModule::test_table_roundtrip \u001b[32mPASSED\u001b[0m\u001b[32m      [ 59%]\u001b[0m\n",
      "tests/test_tables.py::TestTablesModule::test_batch_lookups \u001b[32mPASSED\u001b[0m\u001b[32m        [ 60%]\u001b[0m\n",
      "tests/test_tables.py::TestTablesModule::test_table_size \u001b[32mPASSED\u001b[0m\u001b[32m           [ 61%]\u001b[0m\n",
      "tests/test_tables.py::TestTablesModule::test_tables_with_compressed_vocab \u001b[32mPASSED\u001b[0m\u001b[32m [ 63%]\u001b[0m\n",
      "tests/test_train_loop.py::test_train_one_epoch_runs \u001b[32mPASSED\u001b[0m\u001b[32m               [ 64%]\u001b[0m\n",
      "tests/test_training_utils.py::test_log_training_metrics \u001b[32mPASSED\u001b[0m\u001b[32m           [ 65%]\u001b[0m\n",
      "tests/test_training_utils.py::test_train_step_basic \u001b[32mPASSED\u001b[0m\u001b[32m               [ 66%]\u001b[0m\n",
      "tests/test_training_utils.py::test_train_step_with_clipping \u001b[32mPASSED\u001b[0m\u001b[32m       [ 67%]\u001b[0m\n",
      "tests/test_training_utils.py::test_summarize_dataset_pipeline \u001b[32mPASSED\u001b[0m\u001b[32m     [ 68%]\u001b[0m\n",
      "tests/test_triplets.py::TestTripletsModule::test_write_triplets_from_list \u001b[32mPASSED\u001b[0m\u001b[32m [ 69%]\u001b[0m\n",
      "tests/test_triplets.py::TestTripletsModule::test_write_triplets_from_dataset \u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "tests/test_triplets.py::TestTripletsModule::test_load_triplets_from_tfrecord \u001b[32mPASSED\u001b[0m\u001b[32m [ 71%]\u001b[0m\n",
      "tests/test_triplets.py::TestTripletsModule::test_parse_triplet_example \u001b[32mPASSED\u001b[0m\u001b[32m [ 72%]\u001b[0m\n",
      "tests/test_triplets.py::TestTripletsModule::test_triplets_roundtrip \u001b[32mPASSED\u001b[0m\u001b[32m [ 73%]\u001b[0m\n",
      "tests/test_triplets.py::TestTripletsModule::test_triplets_compression \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
      "tests/test_triplets.py::TestTripletsModule::test_load_compressed_triplets \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
      "tests/test_triplets.py::TestTripletsModule::test_empty_triplets \u001b[32mPASSED\u001b[0m\u001b[32m   [ 77%]\u001b[0m\n",
      "tests/test_triplets.py::TestTripletsModule::test_large_triplets \u001b[32mPASSED\u001b[0m\u001b[32m   [ 78%]\u001b[0m\n",
      "tests/test_vocab.py::TestVocabModule::test_write_vocab_to_tfrecord_basic \u001b[32mPASSED\u001b[0m\u001b[32m [ 79%]\u001b[0m\n",
      "tests/test_vocab.py::TestVocabModule::test_write_vocab_to_tfrecord_with_frequencies \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
      "tests/test_vocab.py::TestVocabModule::test_parse_vocab_example_basic \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\n",
      "tests/test_vocab.py::TestVocabModule::test_parse_vocab_example_with_frequencies \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\n",
      "tests/test_vocab.py::TestVocabModule::test_vocab_roundtrip \u001b[32mPASSED\u001b[0m\u001b[32m        [ 83%]\u001b[0m\n",
      "tests/test_vocab.py::TestVocabModule::test_vocab_compression \u001b[32mPASSED\u001b[0m\u001b[32m      [ 84%]\u001b[0m\n",
      "tests/test_vocab.py::TestVocabModule::test_empty_frequencies \u001b[32mPASSED\u001b[0m\u001b[32m      [ 85%]\u001b[0m\n",
      "tests/test_word2gm_model.py::TestWord2GMModelGPU::test_gpu_compatibility \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 86%]\u001b[0m\n",
      "tests/test_word2gm_model.py::test_model_configurations[1-True-True] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\n",
      "tests/test_word2gm_model.py::test_model_configurations[1-True-False] \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\n",
      "tests/test_word2gm_model.py::test_model_configurations[1-False-True] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
      "tests/test_word2gm_model.py::test_model_configurations[1-False-False] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\n",
      "tests/test_word2gm_model.py::test_model_configurations[2-True-True] \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\n",
      "tests/test_word2gm_model.py::test_model_configurations[2-True-False] \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\n",
      "tests/test_word2gm_model.py::test_model_configurations[2-False-True] \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\n",
      "tests/test_word2gm_model.py::test_model_configurations[2-False-False] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\n",
      "tests/test_word2gm_model.py::test_model_configurations[3-True-True] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\n",
      "tests/test_word2gm_model.py::test_model_configurations[3-True-False] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\n",
      "tests/test_word2gm_model.py::test_model_configurations[3-False-True] \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\n",
      "tests/test_word2gm_model.py::test_model_configurations[3-False-False] \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m======================== \u001b[32m\u001b[1m91 passed\u001b[0m, \u001b[33m1 skipped\u001b[0m\u001b[32m in 25.64s\u001b[0m\u001b[32m ========================\u001b[0m\n",
      "\n",
      "\n",
      "Return code: 0\n",
      "\n",
      "================================================================================\n",
      "SUCCESS: ALL TESTS PASSED!\n",
      "The IO module refactoring is working correctly.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Verify test directory exists and discover test files\n",
    "tests_dir = os.path.join(PROJECT_ROOT, 'tests')\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Tests directory: {tests_dir}\")\n",
    "print(f\"Tests directory exists: {os.path.exists(tests_dir)}\")\n",
    "\n",
    "if os.path.exists(tests_dir):\n",
    "    test_files = [f for f in os.listdir(tests_dir) \n",
    "                  if f.startswith('test_') and f.endswith('.py')]\n",
    "    print(f\"Found {len(test_files)} test files:\")\n",
    "    \n",
    "    # Organize by category\n",
    "    # I/O modules (in the io/ folder)\n",
    "    io_modules = [f for f in test_files if \n",
    "                  any(module in f for module in ['vocab', 'triplets', 'tables', 'artifacts'])]\n",
    "    \n",
    "    # Corpus processing modules \n",
    "    corpus_modules = [f for f in test_files if \n",
    "                      any(module in f for module in ['corpus_to_dataset', 'dataset_to_triplets', 'index_vocab'])]\n",
    "    \n",
    "    # Integration tests\n",
    "    integration_tests = [f for f in test_files if 'integration' in f or 'pipeline' in f]\n",
    "    \n",
    "    # Model training modules (training, model, utilities)\n",
    "    training_modules = [f for f in test_files if f not in io_modules and \n",
    "                        f not in corpus_modules and f not in integration_tests]\n",
    "    \n",
    "    print(f\"  I/O Modules: {io_modules}\")\n",
    "    print(f\"  Corpus Processing Modules: {corpus_modules}\")\n",
    "    print(f\"  Integration Tests: {integration_tests}\")\n",
    "    print(f\"  Model Training Modules: {training_modules}\")\n",
    "else:\n",
    "    print(\"WARNING: Tests directory not found!\")\n",
    "    exit(1)\n",
    "\n",
    "# Import verification\n",
    "print(f\"\\nImport verification...\")\n",
    "try:\n",
    "    from word2gm_fast.io.vocab import write_vocab_to_tfrecord, parse_vocab_example\n",
    "    from word2gm_fast.io.triplets import write_triplets_to_tfrecord, load_triplets_from_tfrecord\n",
    "    from word2gm_fast.io.tables import create_token_to_index_table, create_index_to_token_table\n",
    "    from word2gm_fast.io.artifacts import (save_pipeline_artifacts, load_pipeline_artifacts, \n",
    "                                         save_metadata, load_metadata)\n",
    "    print(\"SUCCESS: All modules imported successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Import verification failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    exit(1)\n",
    "\n",
    "# Run all tests in one comprehensive execution\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RUNNING ALL TESTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "result = subprocess.run([\n",
    "    'python', '-m', 'pytest', \n",
    "    'tests/',\n",
    "    '-v',\n",
    "    '--tb=short'\n",
    "], capture_output=True, text=True, cwd=PROJECT_ROOT)\n",
    "\n",
    "print(\"STDOUT:\")\n",
    "print(result.stdout)\n",
    "if result.stderr:\n",
    "    print(\"\\nSTDERR:\")\n",
    "    print(result.stderr)\n",
    "\n",
    "print(f\"\\nReturn code: {result.returncode}\")\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"SUCCESS: ALL TESTS PASSED!\")\n",
    "    print(\"The IO module refactoring is working correctly.\")\n",
    "    print(\"=\" * 80)\n",
    "else:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"WARNING: Some tests failed.\")\n",
    "    print(\"Review the output above for details.\")\n",
    "    print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a490c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Remote kernel: word2gm-fast2",
   "language": "python",
   "name": "word2gm-fast2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
