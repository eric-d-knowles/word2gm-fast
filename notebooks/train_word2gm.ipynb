{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7c5f9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<pre>Autoreload enabled</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<pre>Project root: /scratch/edk202/word2gm-fast\n",
       "TensorFlow version: 2.19.0\n",
       "Device mode: GPU-enabled</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<pre>Training environment ready!</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set project root directory and add `src` to path\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = '/scratch/edk202/word2gm-fast'\n",
    "project_root = Path(PROJECT_ROOT)\n",
    "src_path = project_root / 'src'\n",
    " \n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "\n",
    "# Import the notebook setup utilities\n",
    "from word2gm_fast.utils.notebook_setup import setup_training_notebook, enable_autoreload, run_silent_subprocess\n",
    "\n",
    "# Enable mixed precision for GPU training\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# Enable autoreload for development\n",
    "enable_autoreload()\n",
    "\n",
    "# Set up environment\n",
    "env = setup_training_notebook(project_root=PROJECT_ROOT)\n",
    "\n",
    "# Extract commonly used modules for convenience\n",
    "tf = env['tensorflow']\n",
    "np = env['numpy']\n",
    "pd = env['pandas']\n",
    "print_resource_summary = env['print_resource_summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51623d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from word2gm_fast.training.notebook_training import run_notebook_training\n",
    "from word2gm_fast.utils.tfrecord_io import load_pipeline_artifacts\n",
    "\n",
    "# Define paths for your small corpus artifacts and output\n",
    "artifacts_dir = '/vast/edk202/NLP_corpora/Google_Books/20200217/eng-fiction/5gram_files/6corpus/yearly_files/data/1937_artifacts'\n",
    "output_dir = '/scratch/edk202/word2gm-fast/output/test_small_corpus'\n",
    "from pathlib import Path\n",
    "Path(output_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d21be501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<pre>Loading pipeline artifacts from: /vast/edk202/NLP_corpora/Google_Books/20200217/eng-fiction/5gram_files/6corpus/yearly_files/data/1937_artifacts</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<pre>Loading vocabulary TFRecord from: /vast/edk202/NLP_corpora/Google_Books/20200217/eng-fiction/5gram_files/6corpus/yearly_files/data/1937_artifacts/vocab.tfrecord</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<pre>Loading triplet TFRecord from: /vast/edk202/NLP_corpora/Google_Books/20200217/eng-fiction/5gram_files/6corpus/yearly_files/data/1937_artifacts/triplets.tfrecord</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<pre>Triplet TFRecord loaded and parsed</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<pre>All artifacts loaded successfully!</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set the path to your artifacts directory (already defined as artifacts_dir)\n",
    "artifacts = load_pipeline_artifacts(artifacts_dir)\n",
    "\n",
    "# Unpack the loaded artifacts\n",
    "vocab_table = artifacts['vocab_table']\n",
    "triplets_ds = artifacts['triplets_ds']\n",
    "vocab_size = artifacts['vocab_size']\n",
    "\n",
    "triplets_ds = triplets_ds.cache()\n",
    "\n",
    "BATCH_SIZE = 5096\n",
    "triplets_ds = triplets_ds.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ed4132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Dataset pipeline structure:\n",
      "üîπ _BatchDataset\n",
      "  üîπ CacheDataset\n",
      "    üîπ _ParallelMapDataset\n",
      "      üîπ _ParallelMapDataset\n",
      "        üîπ TFRecordDatasetV2\n",
      "\n",
      "üöÄ Starting Word2GM training\n",
      "üìù Writing TensorBoard logs to /scratch/edk202/word2gm-fast/output/test_small_corpus/tensorboard\n",
      "\n",
      "üìò Epoch 1/2\n",
      "[Resource] Step 0: CPU 0.0% Mem 8.0% GPU 0.0% GPU Mem 1.8% \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-28 01:02:18.348590: W tensorflow/core/kernels/data/cache_dataset_ops.cc:916] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2025-06-28 01:02:19.930784: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_13}}\n",
      "2025-06-28 01:02:19.930784: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_13}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Resource] Step 1: CPU 10.9% Mem 8.0% GPU 3.0% GPU Mem 1.8% \n",
      "[Resource] Step 2: CPU 12.3% Mem 8.1% GPU 1.0% GPU Mem 1.8% \n",
      "[Resource] Step 2: CPU 12.3% Mem 8.1% GPU 1.0% GPU Mem 1.8% \n",
      "[Resource] Step 3: CPU 12.1% Mem 8.1% GPU 1.0% GPU Mem 1.8% \n",
      "[Resource] Step 3: CPU 12.1% Mem 8.1% GPU 1.0% GPU Mem 1.8% \n",
      "[Resource] Step 4: CPU 12.2% Mem 7.9% GPU 3.0% GPU Mem 1.8% \n",
      "[Resource] Step 4: CPU 12.2% Mem 7.9% GPU 3.0% GPU Mem 1.8% \n",
      "[Resource] Step 5: CPU 12.1% Mem 8.2% GPU 3.0% GPU Mem 1.8% \n",
      "[Resource] Step 5: CPU 12.1% Mem 8.2% GPU 3.0% GPU Mem 1.8% \n",
      "[Resource] Step 6: CPU 12.3% Mem 8.2% GPU 3.0% GPU Mem 1.8% \n",
      "[Resource] Step 6: CPU 12.3% Mem 8.2% GPU 3.0% GPU Mem 1.8% \n",
      "[Resource] Step 7: CPU 11.9% Mem 8.3% GPU 1.0% GPU Mem 1.8% \n",
      "[Resource] Step 7: CPU 11.9% Mem 8.3% GPU 1.0% GPU Mem 1.8% \n",
      "[Resource] Step 8: CPU 12.2% Mem 8.3% GPU 1.0% GPU Mem 1.8% \n",
      "[Resource] Step 8: CPU 12.2% Mem 8.3% GPU 1.0% GPU Mem 1.8% \n",
      "[Resource] Step 9: CPU 12.1% Mem 8.3% GPU 1.0% GPU Mem 1.8% \n",
      "[Resource] Step 9: CPU 12.1% Mem 8.3% GPU 1.0% GPU Mem 1.8% \n",
      "[Resource] Step 10: CPU 12.2% Mem 8.4% GPU 1.0% GPU Mem 1.8% \n",
      "[Resource] Step 10: CPU 12.2% Mem 8.4% GPU 1.0% GPU Mem 1.8% \n",
      "[Resource] Step 11: CPU 12.1% Mem 8.4% GPU 1.0% GPU Mem 1.8% \n",
      "[Resource] Step 11: CPU 12.1% Mem 8.4% GPU 1.0% GPU Mem 1.8% \n"
     ]
    }
   ],
   "source": [
    "# Run the training pipeline\n",
    "run_notebook_training(\n",
    "    training_dataset=triplets_ds,\n",
    "    save_path=output_dir,\n",
    "    vocab_size=vocab_size,  # Set to your actual vocab size\n",
    "    embedding_size=16,\n",
    "    num_mixtures=2,\n",
    "    spherical=True,\n",
    "    learning_rate=0.1,\n",
    "    epochs=2,\n",
    "    adagrad=True,\n",
    "    normclip=True,\n",
    "    norm_cap=5.0,\n",
    "    lower_sig=0.05,\n",
    "    upper_sig=1.0,\n",
    "    wout=False,\n",
    "    tensorboard_log_path=os.path.join(output_dir, 'tensorboard'),\n",
    "    monitor_interval=10,\n",
    "    profile=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3799cc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect output files or model weights (optional)\n",
    "print('Output directory contents:', os.listdir(output_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6876f3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch TensorBoard inside the notebook for live monitoring\n",
    "from tensorboard import notebook as tb_notebook\n",
    "import os\n",
    "tb_logdir = os.path.join(output_dir, 'tensorboard')\n",
    "print(f\"TensorBoard logdir: {tb_logdir}\")\n",
    "tb_notebook.start('--logdir', tb_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8587480d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Remote kernel: word2gm-fast2",
   "language": "python",
   "name": "word2gm-fast2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
