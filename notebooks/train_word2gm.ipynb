{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7c5f9e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<pre>Autoreload enabled</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<pre>Project root: /scratch/edk202/word2gm-fast\n",
       "TensorFlow version: 2.19.0\n",
       "Device mode: GPU-enabled</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<pre>Training environment ready!</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set project root directory and add `src` to path\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = '/scratch/edk202/word2gm-fast'\n",
    "project_root = Path(PROJECT_ROOT)\n",
    "src_path = project_root / 'src'\n",
    "\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "\n",
    "# Import the notebook setup utilities\n",
    "from word2gm_fast.utils.notebook_setup import setup_training_notebook, enable_autoreload, run_silent_subprocess\n",
    "\n",
    "# Enable autoreload for development\n",
    "enable_autoreload()\n",
    "\n",
    "# Set up environment (deterministic=True for reproducibility)\n",
    "env = setup_training_notebook(project_root=PROJECT_ROOT)\n",
    "\n",
    "# Extract commonly used modules for convenience\n",
    "tf = env['tensorflow']\n",
    "np = env['numpy']\n",
    "pd = env['pandas']\n",
    "print_resource_summary = env['print_resource_summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04a9987c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<pre>SYSTEM RESOURCE SUMMARY\n",
       "============================================================\n",
       "Hostname: gr028.hpc.nyu.edu\n",
       "\n",
       "Job Allocation:\n",
       "   CPUs: 14\n",
       "   Memory: 125.0 GB\n",
       "   Requested partitions: rtx8000,v100,a100_2,a100_1,h100_1\n",
       "   Running on: SSH failed: Host key verification failed.\n",
       "   Job ID: 62975003\n",
       "   Node list: gr028\n",
       "\n",
       "GPU Information:\n",
       "   CUDA GPUs detected: 1\n",
       "   GPU 0: Quadro RTX 8000\n",
       "      Memory: 0.5/45.0 GB (44.5 GB free)\n",
       "      Temperature: 31°C\n",
       "      Utilization: GPU 0%, Memory 0%\n",
       "\n",
       "TensorFlow GPU Detection:\n",
       "   TensorFlow detects 1 GPU(s)\n",
       "      /physical_device:GPU:0, Memory growth: True\n",
       "   Built with CUDA: True\n",
       "============================================================</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_resource_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51623d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from word2gm_fast.training.notebook_training import run_notebook_training\n",
    "from word2gm_fast.utils.tfrecord_io import load_pipeline_artifacts\n",
    "\n",
    "# Define paths for your small corpus aartifacts and output\n",
    "artifacts_dir = '/vast/edk202/NLP_corpora/Google_Books/20200217/eng-fiction/5gram_files/6corpus/yearly_files/data/1950_artifacts'\n",
    "output_dir = '/scratch/edk202/word2gm-fast/output/test_small_corpus'\n",
    "from pathlib import Path\n",
    "Path(output_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d21be501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<pre>Loading pipeline artifacts from: /vast/edk202/NLP_corpora/Google_Books/20200217/eng-fiction/5gram_files/6corpus/yearly_files/data/1950_artifacts</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<pre>Loading vocabulary TFRecord from: /vast/edk202/NLP_corpora/Google_Books/20200217/eng-fiction/5gram_files/6corpus/yearly_files/data/1950_artifacts/vocab.tfrecord</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1751215880.530632 1578326 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:2f:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<pre>Loading triplet TFRecord from: /vast/edk202/NLP_corpora/Google_Books/20200217/eng-fiction/5gram_files/6corpus/yearly_files/data/1950_artifacts/triplets.tfrecord</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<pre>Triplet TFRecord loaded and parsed</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<pre>All artifacts loaded successfully!</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build the dataset pipeline: cache → shuffle → batch → prefetch\n",
    "\n",
    "# Set the path to your artifacts directory (already defined as artifacts_dir)\n",
    "artifacts = load_pipeline_artifacts(artifacts_dir)\n",
    "\n",
    "# Unpack the loaded artifacts\n",
    "vocab_table = artifacts['vocab_table']\n",
    "triplets_ds = artifacts['triplets_ds']\n",
    "vocab_size = artifacts['vocab_size']\n",
    "\n",
    "# Build the dataset pipeline: cache -> shuffle -> batch -> prefetch\n",
    "triplets_ds = triplets_ds.cache()\n",
    "\n",
    "BATCH_SIZE = 1024 * 16\n",
    "SHUFFLE_BUFFER_SIZE = BATCH_SIZE * 10\n",
    "triplets_ds = triplets_ds.shuffle(SHUFFLE_BUFFER_SIZE)\n",
    "triplets_ds = triplets_ds.batch(BATCH_SIZE)\n",
    "triplets_ds = triplets_ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3f66cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch type: <class 'tuple'>\n",
      "Element 0: shape=(16384,), dtype=<dtype: 'int32'>, min=9, max=49057\n",
      "Element 1: shape=(16384,), dtype=<dtype: 'int32'>, min=80, max=49137\n",
      "Element 2: shape=(16384,), dtype=<dtype: 'int32'>, min=5, max=49148\n"
     ]
    }
   ],
   "source": [
    "# Diagnostic: Inspect a batch from the training dataset\n",
    "for batch in triplets_ds.take(1):\n",
    "    print(\"Batch type:\", type(batch))\n",
    "    if isinstance(batch, dict):\n",
    "        for k, v in batch.items():\n",
    "            print(f\"{k}: shape={v.shape}, dtype={v.dtype}, min={v.numpy().min()}, max={v.numpy().max()}\")\n",
    "    elif isinstance(batch, (tuple, list)):\n",
    "        for i, v in enumerate(batch):\n",
    "            print(f\"Element {i}: shape={v.shape}, dtype={v.dtype}, min={v.numpy().min()}, max={v.numpy().max()}\")\n",
    "    else:\n",
    "        print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ed4132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset pipeline structure (oldest to newest):\n",
      "  [0] TFRecordDatasetV2\n",
      "  [1] _ParallelMapDataset\n",
      "  [2] _ParallelMapDataset\n",
      "  [3] CacheDataset\n",
      "  [4] _ShuffleDataset\n",
      "  [5] _BatchDataset\n",
      "  [6] _PrefetchDataset\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<pre>\n",
       "Starting Word2GM training</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<pre>Writing TensorBoard logs to /scratch/edk202/word2gm-fast/output/test_small_corpus/tensorboard</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_notebook_training(\n",
    "    training_dataset=triplets_ds,\n",
    "    save_path=output_dir,\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_size=100,\n",
    "    num_mixtures=2,\n",
    "    spherical=True,\n",
    "    learning_rate=0.001,\n",
    "    epochs=10,\n",
    "    adagrad=True,\n",
    "    normclip=True,\n",
    "    norm_cap=5.0,\n",
    "    lower_sig=0.05,\n",
    "    upper_sig=1.0,\n",
    "    wout=False,\n",
    "    tensorboard_log_path=os.path.join(output_dir, 'tensorboard'),\n",
    "    monitor_interval=2,\n",
    "    profile=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee1b2949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max resource usage during training:\n",
      "  cpu_percent: 13.6%\n",
      "  mem_percent: 8.6%\n",
      "  gpu_util: 81%\n",
      "  gpu_mem_percent: 6.056179470486111%\n"
     ]
    }
   ],
   "source": [
    "# Print max resource usage after training (if ResourceMonitor was used)\n",
    "from word2gm_fast.utils.resource_monitor import ResourceMonitor\n",
    "if hasattr(ResourceMonitor, 'get_last_instance') and ResourceMonitor.get_last_instance() is not None:\n",
    "    monitor = ResourceMonitor.get_last_instance()\n",
    "    max_stats = monitor.get_max_stats()\n",
    "    print('Max resource usage during training:')\n",
    "    percent_keys = {'cpu_percent', 'mem_percent', 'gpu_util', 'gpu_mem_percent'}\n",
    "    for k, v in max_stats.items():\n",
    "        if k in percent_keys:\n",
    "            print(f'  {k}: {v}%')\n",
    "        else:\n",
    "            print(f'  {k}: {v}')\n",
    "else:\n",
    "    print('ResourceMonitor instance not found or not used.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3799cc4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory contents: ['model_weights_epoch1.weights.h5', 'tensorboard', 'model_weights_epoch2.weights.h5']\n"
     ]
    }
   ],
   "source": [
    "# Inspect output files or model weights (optional)\n",
    "print('Output directory contents:', os.listdir(output_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6876f3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch TensorBoard inside the notebook for live monitoring\n",
    "from tensorboard import notebook as tb_notebook\n",
    "import os\n",
    "tb_logdir = os.path.join(output_dir, 'tensorboard')\n",
    "print(f\"TensorBoard logdir: {tb_logdir}\")\n",
    "tb_notebook.start('--logdir', tb_logdir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Remote kernel: word2gm-fast2",
   "language": "python",
   "name": "word2gm-fast2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
