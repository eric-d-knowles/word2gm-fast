{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97648f54",
   "metadata": {},
   "source": [
    "# Word2GM Training Notebook (Clean)\n",
    "\n",
    "This notebook provides a streamlined interface for training Word2GM models with pre-processed corpus data.\n",
    "\n",
    "## Contents:\n",
    "1. **Setup**: GPU configuration and imports\n",
    "2. **Data Loading**: Load pre-processed artifacts and setup training data\n",
    "3. **Training Configuration**: Multiple configuration options from conservative to aggressive\n",
    "4. **Model Training**: Execute training with selected configuration\n",
    "5. **Analysis**: TensorBoard visualization and nearest neighbors exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "683781ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-06 19:28:37.006808: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-06 19:28:37.021832: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751844517.038945  252001 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751844517.044076  252001 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1751844517.057416  252001 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751844517.057429  252001 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751844517.057430  252001 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751844517.057431  252001 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-06 19:28:37.063245: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\"  # Optional, may help with fragmentation\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not set memory growth: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f7fd872",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Set project root directory and add `src` to path\n",
    "PROJECT_ROOT = '/scratch/edk202/word2gm-fast'\n",
    "project_root = Path(PROJECT_ROOT)\n",
    "src_path = project_root / 'src'\n",
    "\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from word2gm_fast.models.word2gm_model import Word2GMModel\n",
    "from word2gm_fast.models.config import Word2GMConfig\n",
    "from word2gm_fast.training.notebook_training import run_notebook_training\n",
    "from word2gm_fast.io.artifacts import load_pipeline_artifacts\n",
    "from word2gm_fast.utils.resource_summary import print_resource_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec376e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<pre>SYSTEM RESOURCE SUMMARY\n",
       "============================================================\n",
       "Hostname: gv008.hpc.nyu.edu\n",
       "\n",
       "Job Allocation:\n",
       "   CPUs: 14\n",
       "   Memory: 125.0 GB\n",
       "   Requested partitions: v100,rtx8000,a100_2,a100_1,h100_1\n",
       "   Running on: SSH failed: Host key verification failed.\n",
       "   Job ID: 63438478\n",
       "   Node list: gv008\n",
       "\n",
       "GPU Information:\n",
       "   CUDA GPUs detected: 1\n",
       "   GPU 0: Tesla V100-PCIE-32GB\n",
       "      Memory: 0.3/32.0 GB (31.7 GB free)\n",
       "      Temperature: 28Â°C\n",
       "      Utilization: GPU 0%, Memory 0%\n",
       "\n",
       "TensorFlow GPU Detection:\n",
       "   TensorFlow detects 1 GPU(s)\n",
       "      /physical_device:GPU:0, Memory growth: True\n",
       "   Built with CUDA: True\n",
       "============================================================</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_resource_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a277420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<pre>Loading pipeline artifacts from: /vast/edk202/NLP_corpora/Google_Books/20200217/eng-fiction/5gram_files/6corpus/yearly_files/data/1850_artifacts</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<pre>Loading token-to-index vocabulary TFRecord from: /vast/edk202/NLP_corpora/Google_Books/20200217/eng-fiction/5gram_files/6corpus/yearly_files/data/1850_artifacts/vocab.tfrecord</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1751844521.569451  252001 gpu_process_state.cc:208] Using CUDA malloc Async allocator for GPU: 0\n",
      "I0000 00:00:1751844521.569777  252001 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31141 MB memory:  -> device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:2f:00.0, compute capability: 7.0\n",
      "2025-07-06 19:28:41.695491: I tensorflow/core/kernels/data/tf_record_dataset_op.cc:387] The default buffer size is 262144, which is overridden by the user specified `buffer_size` of 134217728\n",
      "2025-07-06 19:28:41.954156: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2025-07-06 19:28:41.954156: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<pre>Loading index-to-token vocab TFRecord from: /vast/edk202/NLP_corpora/Google_Books/20200217/eng-fiction/5gram_files/6corpus/yearly_files/data/1850_artifacts/vocab.tfrecord</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-06 19:28:42.259889: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<pre>Loading triplet TFRecord from: /vast/edk202/NLP_corpora/Google_Books/20200217/eng-fiction/5gram_files/6corpus/yearly_files/data/1850_artifacts/triplets.tfrecord</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<pre>Triplet TFRecord loaded and parsed</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<pre>All artifacts loaded successfully!</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded vocab_size: 33668\n"
     ]
    }
   ],
   "source": [
    "# Define paths for your corpus artifacts and output\n",
    "dataset_artifacts_dir = (\n",
    "    '/vast/edk202/NLP_corpora/Google_Books/20200217/eng-fiction/5gram_files/6corpus/yearly_files/data/'\n",
    "    '1850_artifacts'\n",
    ")\n",
    "output_dir = '/scratch/edk202/word2gm-fast/output/test_corpus'\n",
    "Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Set TensorBoard log directory\n",
    "tensorboard_log_dir = output_dir + '/tensorboard'\n",
    "\n",
    "# Load pipeline artifacts (vocab, triplets, etc.)\n",
    "artifacts = load_pipeline_artifacts(dataset_artifacts_dir)\n",
    "token_to_index_table = artifacts['token_to_index_table']\n",
    "index_to_token_table = artifacts['index_to_token_table']\n",
    "triplets_ds = artifacts['triplets_ds']\n",
    "vocab_size = artifacts['vocab_size']\n",
    "\n",
    "# Build the dataset pipeline: cache -> shuffle -> batch -> prefetch\n",
    "triplets_ds = triplets_ds.cache()\n",
    "BATCH_SIZE = 128\n",
    "SHUFFLE_BUFFER_SIZE = BATCH_SIZE * 10\n",
    "triplets_ds = triplets_ds.shuffle(SHUFFLE_BUFFER_SIZE)\n",
    "triplets_ds = triplets_ds.batch(BATCH_SIZE)\n",
    "triplets_ds = triplets_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "print(f'Loaded vocab_size: {vocab_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bfff30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index for token 'king': 16702\n",
      "Token for index 2549: beacon\n"
     ]
    }
   ],
   "source": [
    "# Example: Query the token_to_index_table and index_to_token_table\n",
    "test_token = 'king'\n",
    "test_index = 2549\n",
    "\n",
    "# Query token to index\n",
    "token_tensor = tf.constant([test_token])\n",
    "index_result = token_to_index_table.lookup(token_tensor).numpy()[0]\n",
    "print(f\"Index for token '{test_token}':\", index_result)\n",
    "\n",
    "# Query index to token\n",
    "index_tensor = tf.constant([test_index], dtype=tf.int64)\n",
    "token_result = index_to_token_table.lookup(index_tensor).numpy()[0].decode('utf-8')\n",
    "print(f\"Token for index {test_index}:\", token_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "570e5b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random sample of 50 triplets from a single batch:\n",
      "Idx: (anchor, pos, neg)\tTokens: (anchor, pos, neg)\n",
      " 1: (7563, 31187, 24782)\t(day, unexpectedly, renew)\n",
      " 2: (26464, 9, 3374)\t(sensation, abasement, bolivia)\n",
      " 3: (21666, 8558, 17166)\t(part, disdain, learnt)\n",
      " 4: (2907, 27804, 3076)\t(best, spare, bisson)\n",
      " 5: (17622, 9020, 7021)\t(little, dose, cribbage)\n",
      " 6: (19129, 4279, 13933)\t(might, call, hectic)\n",
      " 7: (17852, 6419, 26345)\t(loud, contemptuous, sediment)\n",
      " 8: (2610, 10367, 15524)\t(become, estrange, infusion)\n",
      " 9: (14670, 23067, 23158)\t(hundred, pound, precipitancy)\n",
      "10: (26068, 20956, 3451)\t(scene, one, bootee)\n",
      "11: (26549, 20956, 20375)\t(servant, one, nightingale)\n",
      "12: (1186, 30188, 16174)\t(another, tossed, jaded)\n",
      "13: (14670, 33529, 25683)\t(hundred, yard, sackville)\n",
      "14: (6776, 6536, 22481)\t(could, convince, pinion)\n",
      "15: (14622, 3800, 21945)\t(human, bring, pelt)\n",
      "16: (14670, 7563, 29769)\t(hundred, day, thousandfold)\n",
      "17: (16784, 23164, 13450)\t(know, precise, habitually)\n",
      "18: (26970, 12735, 4404)\t(side, glaze, cannoneer)\n",
      "19: (21847, 24909, 18854)\t(pea, resemble, mela)\n",
      "20: (7563, 20772, 6601)\t(day, occasion, copyist)\n",
      "21: (7535, 20956, 25899)\t(daughter, one, sartorial)\n",
      "22: (7563, 25979, 25896)\t(day, saw, sartin)\n",
      "23: (20896, 13152, 15242)\t(old, gremio, inconvenience)\n",
      "24: (6776, 1218, 14888)\t(could, anticipate, illustrator)\n",
      "25: (15365, 1013, 12769)\t(individual, amuse, gloat)\n",
      "26: (10805, 26798, 8930)\t(face, shin, dombey)\n",
      "27: (17114, 14829, 31273)\t(lay, idly, unguarded)\n",
      "28: (13111, 441, 10004)\t(great, advantage, enfants)\n",
      "29: (12363, 20956, 13055)\t(gangway, one, grappling)\n",
      "30: (29705, 17063, 1467)\t(thing, laughable, archbishopric)\n",
      "31: (9778, 31002, 9967)\t(else, uncomplimentary, end)\n",
      "32: (11940, 21666, 22950)\t(fourth, part, porn)\n",
      "33: (7563, 17134, 11434)\t(day, leader, fitzgerald)\n",
      "34: (14549, 20956, 3501)\t(hour, one, botanical)\n",
      "35: (15996, 20956, 16158)\t(iota, one, jackanapes)\n",
      "36: (29705, 972, 16525)\t(thing, amiss, juryman)\n",
      "37: (14670, 20956, 4491)\t(hundred, one, capulets)\n",
      "38: (23832, 20956, 21758)\t(puritan, one, patentee)\n",
      "39: (22795, 19762, 22177)\t(point, mound, pert)\n",
      "40: (6776, 24434, 13853)\t(could, recognize, headstone)\n",
      "41: (28644, 23363, 4700)\t(sublime, principle, catalepsy)\n",
      "42: (15037, 15182, 20909)\t(important, incidental, olfactory)\n",
      "43: (16656, 20956, 3192)\t(key, one, blessedness)\n",
      "44: (12731, 16729, 16746)\t(glassy, kiss, knapsack)\n",
      "45: (19129, 24357, 28412)\t(might, reasonably, stormily)\n",
      "46: (13566, 4382, 23592)\t(hand, candle, prosaic)\n",
      "47: (16784, 10731, 1824)\t(know, extent, atheist)\n",
      "48: (14670, 14497, 22626)\t(hundred, horseman, plato)\n",
      "49: (12889, 12635, 16717)\t(good, gift, kiosk)\n",
      "50: (29706, 31775, 27813)\t(think, uppermost, sparrow)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-06 19:28:46.941527: W tensorflow/core/kernels/data/cache_dataset_ops.cc:916] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "# Print a random sample of 50 triplets from a single batch of the current corpus, showing both indices and tokens\n",
    "import random\n",
    "\n",
    "# Take a single batch from the dataset\n",
    "for batch in triplets_ds.take(1):\n",
    "    # If batch is a tuple of tensors (anchor, pos, neg), stack and transpose to shape (batch_size, 3)\n",
    "    if isinstance(batch, tuple) and len(batch) == 3:\n",
    "        anchor, pos, neg = [t.numpy() for t in batch]\n",
    "        triplets_batch = list(zip(anchor, pos, neg))\n",
    "    else:\n",
    "        # If batch is a single tensor of shape (batch_size, 3)\n",
    "        triplets_batch = batch.numpy()\n",
    "    break\n",
    "\n",
    "sample_size = min(50, len(triplets_batch))\n",
    "sampled_indices = random.sample(range(len(triplets_batch)), sample_size)\n",
    "sampled_triplets = [triplets_batch[i] for i in sampled_indices]\n",
    "\n",
    "def idx_to_token(idx):\n",
    "    idx_tensor = tf.constant([idx], dtype=tf.int64)\n",
    "    token = index_to_token_table.lookup(idx_tensor).numpy()[0].decode('utf-8')\n",
    "    return token\n",
    "\n",
    "print(f\"Random sample of {sample_size} triplets from a single batch:\")\n",
    "print(\"Idx: (anchor, pos, neg)\\tTokens: (anchor, pos, neg)\")\n",
    "for i, triplet in enumerate(sampled_triplets):\n",
    "    anchor, pos, neg = triplet\n",
    "    anchor_token = idx_to_token(anchor)\n",
    "    pos_token = idx_to_token(pos)\n",
    "    neg_token = idx_to_token(neg)\n",
    "    print(f\"{i+1:2d}: ({anchor}, {pos}, {neg})\\t({anchor_token}, {pos_token}, {neg_token})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aea708dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ee36d0aaac667e3b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ee36d0aaac667e3b\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir $tensorboard_log_dir --port 6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc0db78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting Word2GM training...\n",
      "Vocab size: 33668\n",
      "Output: /scratch/edk202/word2gm-fast/output/test_corpus\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**Word2GM Training Hyperparameters:**\n",
       "\n",
       "| Parameter         | Value                |\n",
       "|-------------------|----------------------|\n",
       "| Vocab size        | `33668`  |\n",
       "| Embedding size    | `200` |\n",
       "| Mixtures          | `1` |\n",
       "| Spherical         | `True`   |\n",
       "| Learning rate     | `0.1` |\n",
       "| Epochs            | `30` |\n",
       "| Adagrad           | `True`     |\n",
       "| Normclip          | `True`    |\n",
       "| Norm cap          | `10.0`    |\n",
       "| Lower sigma       | `0.05`   |\n",
       "| Upper sigma       | `1.5`   |\n",
       "| Wout              | `True`        |\n",
       "| Var scale         | `0.05`   |\n",
       "| Loss epsilon      | `1e-08`|\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Starting epoch 1/30...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1751844533.612207  252419 service.cc:152] XLA service 0x148268012a20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1751844533.612230  252419 service.cc:160]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0\n",
      "2025-07-06 19:28:53.618951: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1751844533.639578  252419 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1751844533.783121  252419 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    }
   ],
   "source": [
    "# Run General-Purpose Word2GM Training\n",
    "# Hardcoded stable configuration for reliable training\n",
    "\n",
    "print(f\"ðŸš€ Starting Word2GM training...\")\n",
    "print(f\"Vocab size: {vocab_size}\")\n",
    "print(f\"Output: {output_dir}\")\n",
    "\n",
    "# Run training with hardcoded stable parameters\n",
    "training_results = run_notebook_training(\n",
    "    training_dataset=triplets_ds,\n",
    "    save_path=output_dir,\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_size=200,           # Good balance of capacity and speed\n",
    "    num_mixtures=1,               # Single Gaussian for simplicity\n",
    "    spherical=True,               # Diagonal covariance\n",
    "    learning_rate=0.1,            # Proven stable rate for Word2GM\n",
    "    epochs=30,                    # Reasonable training duration\n",
    "    adagrad=True,                 # Essential for Word2GM\n",
    "    normclip=True,                # Prevents exploding gradients\n",
    "    norm_cap=10.0,                # Moderate gradient clipping\n",
    "    lower_sig=0.05,               # Balanced variance bounds\n",
    "    upper_sig=1.5,\n",
    "    wout=True,                    # Use output embeddings\n",
    "    tensorboard_log_path=tensorboard_log_dir,\n",
    "    monitor_interval=0.5,         # Regular monitoring\n",
    "    var_scale=0.05,               # Moderate regularization\n",
    "    loss_epsilon=1e-8             # Numerical stability\n",
    ")\n",
    "\n",
    "print(\"âœ… Training completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Remote kernel: word2gm-fast2",
   "language": "python",
   "name": "word2gm-fast2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
