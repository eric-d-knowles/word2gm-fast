{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f7fd872",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-30 14:35:36.344468: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-30 14:35:36.360813: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751308536.377910 2203919 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751308536.383081 2203919 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1751308536.396021 2203919 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751308536.396039 2203919 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751308536.396041 2203919 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751308536.396042 2203919 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-30 14:35:36.400393: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Standard imports for TensorFlow and numpy\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "156c8da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.path: ['/scratch/edk202/word2gm-fast/src', '/ext3/miniforge3/bin', '/ext3/miniforge3/condabin'] ...\n"
     ]
    }
   ],
   "source": [
    "# Set project root directory and add `src` to path\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = '/scratch/edk202/word2gm-fast'\n",
    "project_root = Path(PROJECT_ROOT)\n",
    "src_path = project_root / 'src'\n",
    "\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "\n",
    "# Optionally, print sys.path for debugging\n",
    "print('sys.path:', sys.path[:3], '...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a277420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<pre>Loading pipeline artifacts from: /vast/edk202/NLP_corpora/Google_Books/20200217/eng-fiction/5gram_files/6corpus/yearly_files/data/1750_artifacts</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<pre>Loading vocabulary TFRecord from: /vast/edk202/NLP_corpora/Google_Books/20200217/eng-fiction/5gram_files/6corpus/yearly_files/data/1750_artifacts/vocab.tfrecord</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-30 14:35:38.548166: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2025-06-30 14:35:38.691093: I tensorflow/core/kernels/data/tf_record_dataset_op.cc:387] The default buffer size is 262144, which is overridden by the user specified `buffer_size` of 134217728\n",
      "2025-06-30 14:35:38.732648: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<pre>Loading triplet TFRecord from: /vast/edk202/NLP_corpora/Google_Books/20200217/eng-fiction/5gram_files/6corpus/yearly_files/data/1750_artifacts/triplets.tfrecord</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<pre>Triplet TFRecord loaded and parsed</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<pre>All artifacts loaded successfully!</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded vocab_size: 5143\n"
     ]
    }
   ],
   "source": [
    "# Data loading and pipeline setup\n",
    "from word2gm_fast.utils.tfrecord_io import load_pipeline_artifacts\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Define paths for your small corpus artifacts and output\n",
    "dataset_artifacts_dir = '/vast/edk202/NLP_corpora/Google_Books/20200217/eng-fiction/5gram_files/6corpus/yearly_files/data/1750_artifacts'\n",
    "output_dir = '/scratch/edk202/word2gm-fast/output/test_small_corpus'\n",
    "Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load pipeline artifacts (vocab, triplets, etc.)\n",
    "artifacts = load_pipeline_artifacts(dataset_artifacts_dir)\n",
    "vocab_table = artifacts['vocab_table']\n",
    "triplets_ds = artifacts['triplets_ds']\n",
    "vocab_size = artifacts['vocab_size']\n",
    "\n",
    "# Build the dataset pipeline: cache -> shuffle -> batch -> prefetch\n",
    "triplets_ds = triplets_ds.cache()\n",
    "BATCH_SIZE = 256\n",
    "SHUFFLE_BUFFER_SIZE = BATCH_SIZE * 10\n",
    "triplets_ds = triplets_ds.shuffle(SHUFFLE_BUFFER_SIZE)\n",
    "triplets_ds = triplets_ds.batch(BATCH_SIZE)\n",
    "triplets_ds = triplets_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "print(f'Loaded vocab_size: {vocab_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c44b62c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'start_time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNameError\u001b[39;00m:\n\u001b[32m      9\u001b[39m     config = Word2GMConfig(\n\u001b[32m     10\u001b[39m         vocab_size=vocab_size,\n\u001b[32m     11\u001b[39m         embedding_size=\u001b[32m30\u001b[39m,\n\u001b[32m     12\u001b[39m         num_mixtures=\u001b[32m2\u001b[39m\n\u001b[32m     13\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[43mrun_notebook_training\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtriplets_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_mixtures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnum_mixtures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mspherical\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mspherical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# or config.epochs_to_train\u001b[39;49;00m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43madagrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43madagrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnormclip\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnormclip\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnorm_cap\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnorm_cap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlower_sig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlower_sig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mupper_sig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupper_sig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensorboard_log_path\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmonitor_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvar_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvar_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss_epsilon\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloss_epsilon\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/scratch/edk202/word2gm-fast/src/word2gm_fast/training/notebook_training.py:95\u001b[39m, in \u001b[36mrun_notebook_training\u001b[39m\u001b[34m(training_dataset, save_path, vocab_size, embedding_size, num_mixtures, spherical, learning_rate, epochs, adagrad, normclip, norm_cap, lower_sig, upper_sig, wout, tensorboard_log_path, monitor_interval, profile, var_scale, loss_epsilon)\u001b[39m\n\u001b[32m     90\u001b[39m     model.save_weights(\n\u001b[32m     91\u001b[39m         os.path.join(args.save_path, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmodel_weights_epoch\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.weights.h5\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     92\u001b[39m     )\n\u001b[32m     93\u001b[39m     resource_monitor.log_resource_usage()\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m total_time = time.time() - \u001b[43mstart_time\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m summary_writer.as_default():\n\u001b[32m     97\u001b[39m     tf.summary.scalar(\u001b[33m\"\u001b[39m\u001b[33mtotal_training_time_seconds\u001b[39m\u001b[33m\"\u001b[39m, total_time, step=\u001b[32m0\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'start_time' is not defined"
     ]
    }
   ],
   "source": [
    "# Launch Word2GM training using notebook_training.py with standard hyperparameters\n",
    "from word2gm_fast.training.notebook_training import run_notebook_training\n",
    "from word2gm_fast.models.config import Word2GMConfig\n",
    "\n",
    "# Construct config if not already defined\n",
    "try:\n",
    "    config\n",
    "except NameError:\n",
    "    config = Word2GMConfig(\n",
    "        vocab_size=vocab_size,\n",
    "        embedding_size=30,\n",
    "        num_mixtures=2\n",
    "    )\n",
    "\n",
    "run_notebook_training(\n",
    "    training_dataset=triplets_ds,\n",
    "    save_path=output_dir,\n",
    "    vocab_size=config.vocab_size,\n",
    "    embedding_size=config.embedding_size,\n",
    "    num_mixtures=config.num_mixtures,\n",
    "    spherical=config.spherical,\n",
    "    learning_rate=config.learning_rate,\n",
    "    epochs=3,  # or config.epochs_to_train\n",
    "    adagrad=config.adagrad,\n",
    "    normclip=config.normclip,\n",
    "    norm_cap=config.norm_cap,\n",
    "    lower_sig=config.lower_sig,\n",
    "    upper_sig=config.upper_sig,\n",
    "    wout=config.wout,\n",
    "    tensorboard_log_path=None,\n",
    "    monitor_interval=10,\n",
    "    profile=False,\n",
    "    var_scale=config.var_scale,\n",
    "    loss_epsilon=config.loss_epsilon\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80698ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Remote kernel: word2gm-fast2",
   "language": "python",
   "name": "word2gm-fast2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
