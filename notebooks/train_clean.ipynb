{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "683781ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-03 17:41:24.066832: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-03 17:41:24.083465: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751578884.100693 2515541 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751578884.105993 2515541 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1751578884.119687 2515541 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751578884.119701 2515541 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751578884.119703 2515541 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751578884.119704 2515541 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-03 17:41:24.124111: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\"  # Optional, may help with fragmentation\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not set memory growth: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f7fd872",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Set project root directory and add `src` to path\n",
    "PROJECT_ROOT = '/scratch/edk202/word2gm-fast'\n",
    "project_root = Path(PROJECT_ROOT)\n",
    "src_path = project_root / 'src'\n",
    "\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from word2gm_fast.models.config import Word2GMConfig\n",
    "from word2gm_fast.training.notebook_training import run_notebook_training\n",
    "from word2gm_fast.utils.tfrecord_io import load_pipeline_artifacts\n",
    "from word2gm_fast.utils.resource_summary import print_resource_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec376e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<pre>SYSTEM RESOURCE SUMMARY\n",
       "============================================================\n",
       "Hostname: gv006.hpc.nyu.edu\n",
       "\n",
       "Job Allocation:\n",
       "   CPUs: 14\n",
       "   Memory: 125.0 GB\n",
       "   Requested partitions: v100,rtx8000,a100_2,a100_1,h100_1\n",
       "   Running on: SSH failed: Host key verification failed.\n",
       "   Job ID: 63356746\n",
       "   Node list: gv006\n",
       "\n",
       "GPU Information:\n",
       "   CUDA GPUs detected: 1\n",
       "   GPU 0: Tesla V100-PCIE-32GB\n",
       "      Memory: 0.3/32.0 GB (31.7 GB free)\n",
       "      Temperature: 32Â°C\n",
       "      Utilization: GPU 0%, Memory 0%\n",
       "\n",
       "TensorFlow GPU Detection:\n",
       "   TensorFlow detects 1 GPU(s)\n",
       "      /physical_device:GPU:0, Memory growth: True\n",
       "   Built with CUDA: True\n",
       "============================================================</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_resource_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a277420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<pre>Loading pipeline artifacts from: /vast/edk202/NLP_corpora/Google_Books/20200217/eng-fiction/5gram_files/6corpus/yearly_files/data/1940_artifacts</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<pre>Loading vocabulary TFRecord from: /vast/edk202/NLP_corpora/Google_Books/20200217/eng-fiction/5gram_files/6corpus/yearly_files/data/1940_artifacts/vocab.tfrecord</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-03 17:43:21.203757: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<pre>Loading vocabulary TXT file from: /vast/edk202/NLP_corpora/Google_Books/20200217/eng-fiction/5gram_files/6corpus/yearly_files/data/1940_artifacts/vocab.txt</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<pre>Loading triplet TFRecord from: /vast/edk202/NLP_corpora/Google_Books/20200217/eng-fiction/5gram_files/6corpus/yearly_files/data/1940_artifacts/triplets.tfrecord</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<pre>Triplet TFRecord loaded and parsed</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<pre>All artifacts loaded successfully!</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded vocab_size: 42401\n"
     ]
    }
   ],
   "source": [
    "# Data loading and pipeline setup\n",
    "\n",
    "# Define paths for your corpus artifacts and output\n",
    "dataset_artifacts_dir = (\n",
    "    '/vast/edk202/NLP_corpora/Google_Books/20200217/eng-fiction/5gram_files/6corpus/yearly_files/data/'\n",
    "    '1940_artifacts'\n",
    ")\n",
    "output_dir = '/scratch/edk202/word2gm-fast/output/test_corpus'\n",
    "Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Set TensorBoard log directory\n",
    "tensorboard_log_dir = output_dir + '/tensorboard'\n",
    "\n",
    "# Load pipeline artifacts (vocab, triplets, etc.)\n",
    "artifacts = load_pipeline_artifacts(dataset_artifacts_dir)\n",
    "vocab_table = artifacts['vocab_table']\n",
    "vocab_list = artifacts['vocab_list']\n",
    "triplets_ds = artifacts['triplets_ds']\n",
    "vocab_size = artifacts['vocab_size']\n",
    "\n",
    "# Build the dataset pipeline: cache -> shuffle -> batch -> prefetch\n",
    "triplets_ds = triplets_ds.cache()\n",
    "BATCH_SIZE = 1024 * 6\n",
    "SHUFFLE_BUFFER_SIZE = BATCH_SIZE * 10\n",
    "triplets_ds = triplets_ds.shuffle(SHUFFLE_BUFFER_SIZE)\n",
    "triplets_ds = triplets_ds.batch(BATCH_SIZE)\n",
    "triplets_ds = triplets_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "print(f'Loaded vocab_size: {vocab_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44b62c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "**Word2GM Training Hyperparameters:**\n",
       "\n",
       "| Parameter         | Value                |\n",
       "|-------------------|----------------------|\n",
       "| Vocab size        | `42401`  |\n",
       "| Embedding size    | `200` |\n",
       "| Mixtures          | `1` |\n",
       "| Spherical         | `True`   |\n",
       "| Learning rate     | `0.05` |\n",
       "| Epochs            | `10` |\n",
       "| Adagrad           | `True`     |\n",
       "| Normclip          | `True`    |\n",
       "| Norm cap          | `5.0`    |\n",
       "| Lower sigma       | `0.05`   |\n",
       "| Upper sigma       | `1.0`   |\n",
       "| Wout              | `True`        |\n",
       "| Var scale         | `0.05`   |\n",
       "| Loss epsilon      | `1e-08`|\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Starting epoch 1/10...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1751579005.819620 2515985 service.cc:152] XLA service 0x14faa40149b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1751579005.819652 2515985 service.cc:160]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0\n",
      "2025-07-03 17:43:25.826171: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1751579005.847950 2515985 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1751579005.986270 2515985 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    }
   ],
   "source": [
    "config = Word2GMConfig(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_size=200,\n",
    "    num_mixtures=1,\n",
    "    spherical=True,\n",
    "    norm_cap=5.0,\n",
    "    lower_sig=0.05,\n",
    "    upper_sig=1.0,\n",
    "    var_scale=0.05,\n",
    "    loss_epsilon=1e-8,\n",
    "    wout=True,\n",
    "    max_pe=False,\n",
    ")\n",
    "\n",
    "run_notebook_training(\n",
    "    training_dataset=triplets_ds,\n",
    "    save_path=output_dir,\n",
    "    vocab_size=config.vocab_size,\n",
    "    embedding_size=config.embedding_size,\n",
    "    num_mixtures=config.num_mixtures,\n",
    "    spherical=config.spherical,\n",
    "    learning_rate=0.05,\n",
    "    epochs=10,\n",
    "    adagrad=True,\n",
    "    normclip=True,\n",
    "    norm_cap=config.norm_cap,\n",
    "    lower_sig=config.lower_sig,\n",
    "    upper_sig=config.upper_sig,\n",
    "    var_scale=config.var_scale,\n",
    "    loss_epsilon=config.loss_epsilon,\n",
    "    wout=config.wout,\n",
    "    tensorboard_log_path=tensorboard_log_dir,\n",
    "    monitor_interval=0.5,\n",
    "    profile=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5178472d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch TensorBoard in the notebook\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir $tensorboard_log_dir --port 6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac79c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Save model weights in Keras 3-compatible format ---\n",
    "# After training, re-instantiate the model and save weights with a supported extension\n",
    "from word2gm_fast.models.word2gm_model import Word2GMModel\n",
    "model = Word2GMModel(config)\n",
    "\n",
    "# Build the model by calling it on a dummy input (tuple of three tensors)\n",
    "dummy_input = (\n",
    "    tf.zeros([1], dtype=tf.int32),  # word_ids\n",
    "    tf.zeros([1], dtype=tf.int32),  # pos_ids\n",
    "    tf.zeros([1], dtype=tf.int32),  # neg_ids\n",
    ")\n",
    "model(dummy_input)\n",
    "\n",
    "model.load_weights(output_dir + '/model_weights_epoch10.weights.h5')\n",
    "model.save_weights(output_dir + '/model.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187826d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find nearest neighbors for a given word using Word2GMModel and vocab_list\n",
    "model = Word2GMModel(config)\n",
    "\n",
    "# Build the model by calling it on a dummy input (tuple of three tensors)\n",
    "dummy_input = (\n",
    "    tf.zeros([1], dtype=tf.int32),  # word_ids\n",
    "    tf.zeros([1], dtype=tf.int32),  # pos_ids\n",
    "    tf.zeros([1], dtype=tf.int32),  # neg_ids\n",
    ")\n",
    "model(dummy_input)\n",
    "\n",
    "model.load_weights(output_dir + '/model.weights.h5')\n",
    "\n",
    "# Choose a query word and get its index\n",
    "query_word = 'happy'  # Change this to any word in your vocab\n",
    "try:\n",
    "    query_idx = vocab_list.index(query_word)\n",
    "except ValueError:\n",
    "    raise ValueError(f'Word \"{query_word}\" not found in vocab_list.')\n",
    "\n",
    "# Get nearest neighbor indices (returns indices, distances or a list of (index, distance) pairs)\n",
    "result = model.get_nearest_neighbors(query_idx, k=10)\n",
    "print(\"Result type:\", type(result))\n",
    "print(\"Result:\", result)\n",
    "\n",
    "# Try to unpack if possible, else treat as list of pairs\n",
    "try:\n",
    "    neighbor_indices, neighbor_distances = result\n",
    "    neighbors = [(vocab_list[i], float(d)) for i, d in zip(neighbor_indices, neighbor_distances)]\n",
    "except Exception:\n",
    "    neighbors = [(vocab_list[i], float(d)) for i, d in result]\n",
    "\n",
    "print(f'Nearest neighbors for \"{query_word}\":')\n",
    "for word, dist in neighbors:\n",
    "    print(f'{word}\\t{dist:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2262df2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the distribution of learned means for a few random words\n",
    "import numpy as np\n",
    "\n",
    "# Get the means tensor (shape: [vocab_size, num_mixtures, embedding_size])\n",
    "means = model.mus.numpy()  # or model.mus_out if wout=True and use_output\n",
    "\n",
    "print(\"Means shape:\", means.shape)\n",
    "for idx in np.random.choice(means.shape[0], size=5, replace=False):\n",
    "    print(f\"Word: {vocab_list[idx]}\")\n",
    "    print(\"  Mean (first mixture):\", means[idx, 0, :5])  # print first 5 dims\n",
    "    print(\"  Mean std (all mixtures):\", means[idx].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97fcac7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Remote kernel: word2gm-fast2",
   "language": "python",
   "name": "word2gm-fast2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
